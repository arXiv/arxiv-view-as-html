@article{cheng2021per,
  title={Per-pixel classification is not all you need for semantic segmentation},
  author={Cheng, Bowen and Schwing, Alex and Kirillov, Alexander},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={17864--17875},
  year={2021}
}

@article{niu2021review,
  title={A review on the attention mechanism of deep learning},
  author={Niu, Zhaoyang and Zhong, Guoqiang and Yu, Hui},
  journal={Neurocomputing},
  volume={452},
  pages={48--62},
  year={2021},
  publisher={Elsevier}
}

@article{yang2020hyperparameter,
  title={On hyperparameter optimization of machine learning algorithms: Theory and practice},
  author={Yang, Li and Shami, Abdallah},
  journal={Neurocomputing},
  volume={415},
  pages={295--316},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{loshchilov10sgdr,
	title={{SGDR}: Stochastic Gradient Descent with Warm Restarts},
	author={Ilya Loshchilov and Frank Hutter},
	booktitle={Proceedings of the 5th International Conference on Learning Representations},
	month = {April},
	year = {2017},
	url={https://openreview.net/forum?id=Skq89Scxx},
}

@inproceedings{mihaylova-martins-2019-scheduled,
	title = "Scheduled Sampling for Transformers",
	author = "Mihaylova, Tsvetomila  and
	Martins, Andr{\'e} F. T.",
	booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop",
	month = jul,
	year = "2019",
	address = "Florence, Italy",
	publisher = "Association for Computational Linguistics",
	url = "https://aclanthology.org/P19-2049",
	doi = "10.18653/v1/P19-2049",
	pages = "351--356",
	abstract = "Scheduled sampling is a technique for avoiding one of the known problems in sequence-to-sequence generation: exposure bias. It consists of feeding the model a mix of the teacher forced embeddings and the model predictions from the previous step in training time. The technique has been used for improving model performance with recurrent neural networks (RNN). In the Transformer model, unlike the RNN, the generation of a new word attends to the full sentence generated so far, not only to the last word, and it is not straightforward to apply the scheduled sampling technique. We propose some structural changes to allow scheduled sampling to be applied to Transformer architectures, via a two-pass decoding strategy. Experiments on two language pairs achieve performance close to a teacher-forcing baseline and show that this technique is promising for further exploration.",
}

@article{qiao2020deep,
	title={Deep learning based software defect prediction},
	author={Qiao, Lei and Li, Xuesong and Umer, Qasim and Guo, Ping},
	journal={Neurocomputing},
	volume={385},
	pages={100--110},
	year={2020},
	publisher={Elsevier}
}

@article{lin2020software,
	title={Software vulnerability detection using deep neural networks: a survey},
	author={Lin, Guanjun and Wen, Sheng and Han, Qing-Long and Zhang, Jun and Xiang, Yang},
	journal={Proceedings of the IEEE},
	volume={108},
	number={10},
	pages={1825--1848},
	year={2020},
	publisher={IEEE}
}

@inproceedings {xue280012,
  author = {Diwen Xue and Reethika Ramesh and Arham Jain and Michalis Kallitsis and J. Alex Halderman and Jedidiah R. Crandall and Roya Ensafi},
  title = {{OpenVPN} is Open to {VPN} Fingerprinting},
  booktitle = {31st USENIX Security Symposium (USENIX Security 22)},
  year = {2022},
  isbn = {978-1-939133-31-1},
  address = {Boston, MA},
  pages = {483--500},
  url = {https://www.usenix.org/conference/usenixsecurity22/presentation/xue-diwen},
  publisher = {USENIX Association},
  month = aug,
}

@inproceedings{zhu2013velocity,
	title={The Velocity of Censorship:$\{$High-Fidelity$\}$ Detection of Microblog Post Deletions},
	author={Zhu, Tao and Phipps, David and Pridgen, Adam and Crandall, Jedidiah R and Wallach, Dan S},
	booktitle={22nd USENIX Security Symposium (USENIX Security 13)},
	pages={227--240},
	year={2013}
}

@inproceedings{barradas2018effective,
  title={Effective detection of multimedia protocol tunneling using machine learning},
  author={Barradas, Diogo and Santos, Nuno and Rodrigues, Lu{\'\i}s},
  booktitle={27th USENIX Security Symposium (USENIX Security 18)},
  pages={169--185},
  year={2018}
}

@inproceedings{trivedi2016fully,
  title={A fully automated deep packet inspection verification system with machine learning},
  author={Trivedi, Uday and Patel, Munal},
  booktitle={2016 IEEE International Conference on Advanced Networks and Telecommunications Systems (ANTS)},
  pages={1--6},
  year={2016},
  organization={IEEE}
}

@inproceedings{chin2018explicit,
	title={Explicit content detection in music lyrics using machine learning},
	author={Chin, Hyojin and Kim, Jayong and Kim, Yoonjong and Shin, Jinseop and Yi, Mun Y},
	booktitle={2018 IEEE International Conference on Big Data and Smart Computing (BigComp)},
	pages={517--521},
	year={2018},
	organization={IEEE}
}

@inproceedings{afsha2022machine,
	title={Machine Learning Models for Content Classification in Film Censorship and Rating},
	author={Afsha, Syma and Haque, Mahmudul and Nyeem, Hussain},
	booktitle={2022 International Conference on Innovations in Science, Engineering and Technology (ICISET)},
	pages={396--401},
	year={2022},
	organization={IEEE}
}


@article{jin2021understanding,
  title={Understanding the Practices of Global Censorship through Accurate, End-to-End Measurements},
  author={Jin, Lin and Hao, Shuai and Wang, Haining and Cotton, Chase},
  journal={Proceedings of the ACM on Measurement and Analysis of Computing Systems},
  volume={5},
  number={3},
  pages={1--25},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{ververis2021understanding,
	title={Understanding {Internet} Censorship in {Europe}: The Case of {Spain}},
	author={Ververis, Vasilis and Ermakova, Tatiana and Isaakidis, Marios and Basso, Simone and Fabian, Benjamin and Milan, Stefania},
	booktitle={13th ACM Web Science Conference 2021},
	pages={319--328},
	year={2021}
}

@inproceedings{padmanabhan2021multi,
	title={A multi-perspective view of {Internet} censorship in {Myanmar}},
	author={Padmanabhan, Ramakrishna and Filast{\`o}, Arturo and Xynou, Maria and Raman, Ram Sundara and Middleton, Kennedy and Zhang, Mingwei and Madory, Doug and Roberts, Molly and Dainotti, Alberto},
	booktitle={Proceedings of the ACM SIGCOMM 2021 Workshop on Free and Open Communications on the Internet},
	pages={27--36},
	year={2021}
}

@inproceedings{bock2021even,
	title={Even Censors Have a Backup: Examining {China}'s Double {HTTPS} Censorship Middleboxes},
	author={Bock, Kevin and Naval, Gabriel and Reese, Kyle and Levin, Dave},
	booktitle={Proceedings of the ACM SIGCOMM 2021 Workshop on Free and Open Communications on the Internet},
	pages={1--7},
	year={2021}
}

@inproceedings{singh2017characterizing,
	title={Characterizing the nature and dynamics of {Tor} exit blocking},
	author={Singh, Rachee and Nithyanand, Rishab and Afroz, Sadia and Pearce, Paul and Tschantz, Michael Carl and Gill, Phillipa and Paxson, Vern},
	booktitle={26th USENIX Security Symposium (USENIX Security 17)},
	pages={325--341},
	year={2017}
}

@inproceedings{ng2018detecting,
	title={Detecting censorable content on {Sina} {Weibo}: A pilot study},
	author={Ng, Kei Yin and Feldman, Anna and Leberknight, Chris},
	booktitle={Proceedings of the 10th Hellenic Conference on Artificial Intelligence},
	pages={1--5},
	year={2018}
}

@misc{pytorchdensenet,
	author={{Pytorch Team}},
	title={{DenseNet}},
	note={Available: \url{https://pytorch.org/hub/pytorch_vision_densenet/},
		retrieved Auguest 31, 2021},
}

@inproceedings{zhu2017densenet,
  title={Densenet for dense flow},
  author={Zhu, Yi and Newsam, Shawn},
  booktitle={2017 IEEE international conference on image processing (ICIP)},
  pages={790--794},
  year={2017},
  organization={IEEE}
}

@inproceedings{chen2020software,
	title={Software visualization and deep transfer learning for effective software defect prediction},
	author={Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
	booktitle={Proceedings of the ACM/IEEE 42nd international conference on software engineering},
	pages={578--589},
	year={2020}
}

@inproceedings{rezende2014stochastic,
	title={Stochastic backpropagation and approximate inference in deep generative models},
	author={Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
	booktitle={International conference on machine learning},
	pages={1278--1286},
	year={2014},
	organization={PMLR}
}

@inproceedings{conneau2020unsupervised,
	title={Unsupervised Cross-lingual Representation Learning at Scale},
	author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, {\'E}douard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
	booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
	pages={8440--8451},
	year={2020}
}

@inproceedings{yadav2018light,
	title={Where the light gets in: Analyzing {Web} censorship mechanisms in {India}},
	author={Yadav, Tarun Kumar and Sinha, Akshat and Gosain, Devashish and Sharma, Piyush Kumar and Chakravarty, Sambuddho},
	booktitle={Proceedings of the Internet Measurement Conference 2018},
	pages={252--264},
	year={2018},
        doi={https://doi.org/10.1145/3278532.3278555}
}

@inproceedings{jones2014automated,
  title={Automated detection and fingerprinting of censorship block pages},
  author={Jones, Ben and Lee, Tzu-Wen and Feamster, Nick and Gill, Phillipa},
  booktitle={Proceedings of the 2014 Conference on Internet Measurement Conference},
  pages={299--304},
  year={2014}
}

@mastersthesis{li2015predicting,
	title={Predicting Large-Scale {Internet} Censorship--A Machine Learning Approach},
	author={Li, Jin},
	year={2015},
	school={the School of Engineering and Applied Science, the University of
		Virginia},
	note={available: \url{https://libra2.lib.virginia.edu/downloads/d504rk52c}}
}

@inproceedings{gao2021machine,
	title={Machine Learning Based Network Censorship},
	author={Gao, Xiangyu and Qiu, Meikang and Liu, Meiqin},
	booktitle={2021 8th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2021 7th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom)},
	pages={149--154},
	year={2021},
	organization={IEEE}
}

@inproceedings{morrison2015challenges,
	title={Challenges with applying vulnerability prediction models},
	author={Morrison, Patrick and Herzig, Kim and Murphy, Brendan and Williams, Laurie},
	booktitle={Proceedings of the 2015 Symposium and Bootcamp on the Science of Security},
	pages={1--9},
	year={2015}
}

@inproceedings{vandersloot2018quack,
  title={Quack: Scalable Remote Measurement of {Application-Layer} Censorship},
  author={VanderSloot, Benjamin and McDonald, Allison and Scott, Will and Halderman, J Alex and Ensafi, Roya},
  booktitle={27th USENIX Security Symposium (USENIX Security 18)},
  pages={187--202},
  year={2018}
}

@inproceedings{scott2016satellite,
  title={Satellite: Joint Analysis of {CDNs} and {Network-Level} Interference},
  author={Scott, Will and Anderson, Thomas and Kohno, Tadayoshi and Krishnamurthy, Arvind},
  booktitle={2016 USENIX Annual Technical Conference (USENIX ATC 16)},
  pages={195--208},
  year={2016}
}

@inproceedings{pearce2017global,
  title={Global measurement of {DNS} manipulation},
  author={Pearce, Paul and Jones, Ben and Li, Frank and Ensafi, Roya and Feamster, Nick and Weaver, Nick and Paxson, Vern},
  booktitle={26th USENIX Security Symposium (USENIX Security 17)},
  pages={307--323},
  year={2017}
}


@inproceedings{pearce2017augur,
  title={Augur: {Internet-wide} detection of connectivity disruptions},
  author={Pearce, Paul and Ensafi, Roya and Li, Frank and Feamster, Nick and Paxson, Vern},
  booktitle={2017 IEEE Symposium on Security and Privacy (SP)},
  pages={427--443},
  year={2017},
  organization={IEEE}
}

@article{chen2000pornography,
	title={Pornography, protection, prevarication: the politics of {Internet} censorship.},
	author={Chen, Peter},
	journal={University of New South Wales Law Journal},
	volume={23},
	number={1},
	pages={221--226},
	year={2000}
}

@article{meserve2018google,
	title={Google politics: The political determinants of {Internet} censorship in democracies},
	author={Meserve, Stephen A and Pemstein, Daniel},
	journal={Political Science Research and Methods},
	volume={6},
	number={2},
	pages={245--263},
	year={2018},
	publisher={Cambridge University Press}
}

@article{shishkina2018internet,
	title={{Internet} censorship in {Arab} countries: Religious and moral aspects},
	author={Shishkina, Alisa and Issaev, Leonid},
	journal={Religions},
	volume={9},
	number={11},
	pages={358},
	year={2018},
	publisher={MDPI}
}

@inproceedings{chai2019importance,
	title={On the Importance of {Encrypted-SNI} ({ESNI}) to Censorship Circumvention},
	author={Chai, Zimo and Ghafari, Amirhossein and Houmansadr, Amir},
	booktitle={9th USENIX Workshop on Free and Open Communications on the Internet (FOCI 19)},
	year={2019}
}

@inproceedings{satija2021blindtls,
	title={BlindTLS: Circumventing {TLS}-based HTTPS censorship},
	author={Satija, Sambhav and Chatterjee, Rahul},
	booktitle={Proceedings of the ACM SIGCOMM 2021 Workshop on Free and Open Communications on the Internet},
	pages={43--49},
	year={2021}
}

@inproceedings{winter2012great,
	title={How the {Great Firewall of China} is Blocking {Tor}},
	author={Winter, Philipp and Lindskog, Stefan},
	booktitle={2nd USENIX Workshop on Free and Open Communications on the Internet, Bellevue, WA},
	pages={7},
	year={2012},
	organization={USENIX-The Advanced Computing Systems Association}
}

@inproceedings{filasto2012ooni,
	title={{OONI}: Open Observatory of Network Interference},
	author={Filast{\`o}, A and Appelbaum, J},
	booktitle={2nd USENIX Workshop on Free and Open Communications on the Internet (FOCI 2012)},
	year={2012}
}

@inproceedings{niaki2020iclab,
	title={{ICLab}: A global, longitudinal {Internet} censorship measurement platform},
	author={Niaki, Arian Akhavan and Cho, Shinyoung and Weinberg, Zachary and Hoang, Nguyen Phong and Razaghpanah, Abbas and Christin, Nicolas and Gill, Phillipa},
	booktitle={2020 IEEE Symposium on Security and Privacy (SP)},
	pages={135--151},
	year={2020},
	organization={IEEE}
}

@inproceedings{huang_densely_2017,
	address = {Honolulu, Hawaii, USA},
	title = {Densely {Connected} {Convolutional} {Networks}},
	doi = {10.1109/CVPR.2017.243},
	abstract = {Recent work has shown that convolutional networks can be substantially deeper, more accurate, and efficient to train if they contain shorter connections between layers close to the input and those close to the output. In this paper, we embrace this observation and introduce the Dense Convolutional Network (DenseNet), which connects each layer to every other layer in a feed-forward fashion. Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L(L+1)/2 direct connections. For each layer, the feature-maps of all preceding layers are used as inputs, and its own feature-maps are used as inputs into all subsequent layers. DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. We evaluate our proposed architecture on four highly competitive object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet). DenseNets obtain significant improvements over the state-of-the-art on most of them, whilst requiring less memory and computation to achieve high performance. Code and pre-trained models are available at https://github.com/liuzhuang13/DenseNet.},
	booktitle = {2017 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {Curran Associates1},
	author = {Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q.},
	month = jul,
	year = {2017},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {2261--2269},
}

@inproceedings{sutskever_sequence_2014,
	address = {Montreal, Canada},
	title = {Sequence to {Sequence} {Learning} with {Neural} {Networks}},
	volume = {1},
	url = {http://arxiv.org/abs/1409.3215},
	abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT'14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous best result on this task. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
	urldate = {2021-07-27},
	booktitle = {28th {Annual} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	month = dec,
	year = {2014},
	note = {arXiv: 1409.3215},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	pages = {3104--3112},
}

@inproceedings{devlin_bert_2019,
	address = {Minneapolis, Minnesota},
	title = {{BERT}: {Pre}-training of {Deep} {Bidirectional} {Transformers} for {Language} {Understanding}},
	volume = {1},
	url = {https://aclanthology.org/N19-1423},
	doi = {10.18653/v1/N19-1423},
	abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7\% (4.6\% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	booktitle = {Proceedings of the 2019 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics}: {Human} {Language} {Technologies}, {Volume} 1 ({Long} and {Short} {Papers})},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	month = jun,
	year = {2019},
	keywords = {Computer Science - Computation and Language},
	pages = {4171--4186},
}

@inproceedings{conneau_cross-lingual_2019,
	address = {Vancouver Convention Center, Vancouver, British Columbia, Canada},
	title = {Cross-lingual {Language} {Model} {Pretraining}},
	volume = {9},
	isbn = {978-1-71380-793-3},
	url = {https://proceedings.neurips.cc/paper/2019/hash/c04c19c2c2474dbf5f7ac4372c5b9af1-Abstract.html},
	urldate = {2022-02-24},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 32},
	publisher = {Curran Associates, Inc.},
	author = {CONNEAU, Alexis and Lample, Guillaume},
	year = {2019},
	pages = {7027--7037},
}

@misc{li_fei-fei_imagenet_2012,
	type = {Competition},
	title = {{ImageNet} {Large} {Scale} {Visual} {Recognition} {Challenge} 2012 ({ILSVRC2012})},
	url = {https://image-net.org/challenges/LSVRC/2012/},
	abstract = {The goal of this competition is to estimate the content of photographs for the purpose of retrieval and automatic annotation using a subset of the large hand-labeled ImageNet dataset (10,000,000 labeled images depicting 10,000+ object categories) as training. Test images will be presented with no initial annotation -- no segmentation or labels -- and algorithms will have to produce labelings specifying what objects are present in the images. New test images will be collected and labeled especially for this competition and are not part of the previously published ImageNet dataset. The general goal is to identify the main objects present in images. This year, we also have a detection task of specifying the location of objects.},
	urldate = {2022-03-11},
	journal = {ImageNet},
	author = {{Li Fei-Fei}},
	collaborator = {{Jia Deng} and {Olga Russakovsky} and {Alex Berg} and {Kai Li}},
	month = may,
	year = {2012},
}

@misc{sarah_laplante_blockpage_2021,
	title = {Blockpage and {False} {Positive} {Signatures} from {Censored} {Planet} {Analysis}},
	url = {https://github.com/censoredplanet/censoredplanet-analysis/tree/master/pipeline/metadata/data},
	urldate = {2021-06-05},
	author = {{Sarah Laplante}},
	month = apr,
	year = {2021},
}

@phdthesis{shu_data_2014,
	type = {Thesis},
	title = {Data {Mining} of {Chinese} {Social} {Media}},
	url = {https://scholarship.rice.edu/handle/1911/88119},
	abstract = {We present measurements and analysis of censorship on Weibo, a popular microblogging site in China. Since we were limited in the rate at which we could download posts, we identified users likely to participate in sensitive topics and recursively followed their social contacts, biasing our search toward a subset of Weibo where we hoped to be more likely to observe censorship. Our architecture enables us to detect post deletions within one minute of the deletion event, giving us a high-fidelity view of what is being deleted by the censors and when.
     
We found that deletions happen most heavily in the first hour after a post has been submitted. Focusing on original posts, not reposts/retweets, we observed that nearly 30\% of the total deletion events occur within 5-30 minutes. Nearly 90\% of the deletions happen within the first 24 hours.
     
Leveraging our data, we also consider a variety of hypotheses about the mechanisms used by Weibo for censorship, such as the extent to which they use retrospective keyword-based censorship, and how repost/retweet popularity interacts with censorship.
     
By leveraging natural language processing techniques we also perform a topical analysis of the deleted posts, overcoming the usage of neologisms, named entities, and informal language that typifies Chinese social media. Using Independent Component Analysis, we find that the topics where mass removal happens the fastest are those that combine events that are hot topics in Weibo as a whole (e.g., the Beijing rainstorms or a sex scandal) with themes common to sensitive posts (e.g., Beijing, government, China, and policeman). 

Air pollution is a pressing concern for industrialized countries. Air quality measurements and their interpretations often take on political overtones. Similar concerns reflect the our understanding of what levels of measured pollution correspond to different levels of human nuisance, impairment, or injury. In this paper, we consider air pollution metrics from four large Chinese cities (U.S. embassy/consulate data, and Chinese domestic measurements) and compare them to a large volume of discussions on Weibo (a popular Chinese microblogging system). In the city with the worst PM2.5, Beijing, we found a strong correlation (R=0.82) between Chinese use of pollution-related terms and the ambient pollution. In other Chinese cities with lower pollution, the correlation was weaker. Nonetheless, our results show that social media may be a valuable proxy measurement for pollution, which may be quite valuable when traditional measurement stations are unavailable (or whose output is censored or misreported).},
	language = {eng},
	urldate = {2022-03-08},
	school = {Rice University},
	author = {Shu, Anhei},
	month = oct,
	year = {2014},
	note = {Accepted: 2016-01-25T21:29:03Z},
}

@misc{maxime_what_2020,
	title = {What is a {Transformer}?},
	url = {https://medium.com/inside-machine-learning/what-is-a-transformer-d07dd1fbec04},
	abstract = {An Introduction to Transformers and Sequence-to-Sequence Learning for Machine Learning},
	language = {en},
	urldate = {2022-02-26},
	journal = {Inside Machine learning},
	author = {Maxime},
	month = mar,
	year = {2020},
}

@inproceedings{bahdanau_neural_2016,
	address = {San Diego, CA},
	title = {Neural {Machine} {Translation} by {Jointly} {Learning} to {Align} and {Translate}},
	url = {http://arxiv.org/abs/1409.0473},
	abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder–decoders and encode a source sentence into a ﬁxed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a ﬁxed-length vector is a bottleneck in improving the performance of this basic encoder–decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
	language = {en},
	urldate = {2022-02-26},
	booktitle = {{arXiv}:1409.0473 [cs, stat]},
	author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	month = may,
	year = {2016},
	note = {arXiv: 1409.0473},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@misc{kanstren_look_2021,
	title = {A {Look} at {Precision}, {Recall}, and {F1}-{Score}},
	url = {https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec},
	abstract = {Exploring the relations between machine learning metrics.},
	language = {en},
	urldate = {2022-02-24},
	journal = {Medium},
	author = {Kanstrén, Teemu},
	month = may,
	year = {2021},
}

@misc{common_crawl_what_2022,
	type = {Non-profit},
	title = {What is {Common} {Crawl}},
	shorttitle = {About {Common} {Crawl}},
	url = {https://commoncrawl.org/about/},
	abstract = {The Common Crawl Foundation is a California 501(c)(3) registered non-profit founded by Gil Elbaz with the goal of democratizing access to web information by producing and maintaining an open repository of web crawl data that is universally accessible and analyzable.},
	language = {en-US},
	urldate = {2022-02-24},
	journal = {Common Crawl},
	author = {{Common Crawl}},
	year = {2022},
}

@misc{niemietz_english_2007,
	title = {English:  {Sample} image rendered with the grayscale indexed palette},
	copyright = {Public domain},
	shorttitle = {English},
	url = {https://commons.wikimedia.org/wiki/File:Grayscale_8bits_palette_sample_image.png},
	urldate = {2022-02-16},
	author = {Niemietz, Ricardo Cancho},
	year = {2007},
}

@article{szegedy_going_2014,
	title = {Going {Deeper} with {Convolutions}},
	url = {http://arxiv.org/abs/1409.4842},
	abstract = {We propose a deep convolutional neural network architecture codenamed "Inception", which was responsible for setting the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC 2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC 2014 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection.},
	urldate = {2022-02-07},
	journal = {arXiv:1409.4842 [cs]},
	author = {Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
	month = sep,
	year = {2014},
	note = {arXiv: 1409.4842},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{noauthor_densenet_2020,
	title = {{DenseNet} {Architecture} {Explained} with {PyTorch} {Implementation} from {TorchVision}},
	url = {https://amaarora.github.io/2020/08/02/densenets.html},
	abstract = {Introduction DenseNet Architecture Introduction But is feature concatenation possible? Transition Layers Dense connectivity Inside a single DenseBlock DenseNet Architecture as a collection of DenseBlocks Bottleneck Layers DenseNet Implementation DenseLayer Implementation DenseBlock Implementation DenseNet Architecture Implementation Conclusion Credits Introduction In this post today, we will be looking at DenseNet architecture from the research paper Densely Connected Convolutional Networks. The overall agenda is to: Understand what DenseNet architecture is Introduce dense blocks, transition layers and look at a single dense block in more detail Understand step-by-step the TorchVision implementation of DenseNet DenseNet Architecture Introduction In a standard Convolutional Neural Network, we have an input image, that is then passed through the network to get an output predicted label in a way where the forward pass is pretty straightforward as shown in the image below: Each convolutional layer except the first one (which takes in the input image), takes in the output of the previous convolutional layer and produces an output feature map that is then passed to next convolutional layer. For L layers, there are L direct connections - one between each layer and its subsequent layer. The DenseNet architecture is all about modifying this standard CNN architecture like so: In a DenseNet architecture, each layer is connected to every other layer, hence the name Densely Connected Convolutional Network. For L layers, there are L(L+1)/2 direct connections. For each layer, the feature maps of all the preceding layers are used as inputs, and its own feature maps are used as input for each subsequent layers. This is really it, as simple as this may sound, DenseNets essentially conect every layer to every other layer. This is the main idea that is extremely powerful. The input of a layer inside DenseNet is the concatenation of feature maps from previous layers. From the paper: DenseNets have several compelling advantages: they alleviate the vanishing-gradient problem, strengthen feature propagation, encourage feature reuse, and substantially reduce the number of parameters. But is feature concatenation possible? Okay, so then, now we know the input of Lth layer are the feature maps from [L1, L1, L1.. L-1th] concatenated but is this concatenation possible? At this point in time, I want you to think about whether we can concat the features from the first layer of a DenseNet with the last layer of the DenseNet? If we can, why? If we can’t, what do we need to do to make this possible? This is a good time to take a minute and think about this question. So, here’s what I think - it would not be possible to concatenate the feature maps if the size of feature maps is different. So, to be able to perform the concatenation operation, we need to make sure that the size of the feature maps that we are concatenating is the same. Right? But we can’t just keep the feature maps the same size throughout the network - an essential part of concvolutional networks is down-sampling layers that change the size of feature maps. For example, look at the VGG architecture below: The input of shape 224x224x3 is downsampled to 7x7x512 towards the end of the network. To facilitate both down-sampling in the architecture and feature concatenation - the authors divided the network into multiple densely connected dense blocks. Inside the dense blocks, the feature map size remains the same. Dividing the network into densely connected blocks solves the problem that we discussed above. Now, the Convolution + Pooling operations outside the dense blocks can perform the downsampling operation and inside the dense block we can make sure that the size of the feature maps is the same to be able to perform feature concatenation. Transition Layers The authors refer to the layers between the dense blocks as transition layers which do the convolution and pooling. From the paper, we know that the transition layers used in the DenseNet architecture consist of a batch-norm layer, 1x1 convolution followed by a 2x2 average pooling layer. Given that the transition layers are pretty easy, let’s quickly implement them here: class \_Transition(nn.Sequential): def \_\_init\_\_(self, num\_input\_features, num\_output\_features): super(\_Transition, self).\_\_init\_\_() self.add\_module('norm', nn.BatchNorm2d(num\_input\_features)) self.add\_module('relu', nn.ReLU(inplace=True)) self.add\_module('conv', nn.Conv2d(num\_input\_features, num\_output\_features, kernel\_size=1, stride=1, bias=False)) self.add\_module('pool', nn.AvgPool2d(kernel\_size=2, stride=2)) Essentially the 1x1 conv performs the downsampling from num\_input\_features to num\_output\_features. Dense connectivity Let’s consider a network with L layers, each of which performs a non-linear transformation HL. The output of the Lth layer of the network is denoted as xL and the input image is represented as x0. We know that traditional feed-forward netowrks connect the output of the Lth layer to L+1th layer. And the skip connection can be represented as: In DenseNet architecture, the dense connectivity can be represented as: where [x0, x1, x2..] represents concatenation of the feature maps produced by [0,1,.. Lth] layers. Inside a single DenseBlock Now that we understand that a DenseNet architecture is divided into multiple dense blocks, let’s look at a single dense block in a little more detail. Essentially, we know, that inside a dense block, each layer is connected to every other layer and the feature map size remains the same. Let’s try and understand what’s really going on inside a dense block. We have some gray input features that are then passed to LAYER\_0. The LAYER\_0 performs a non-linear transformation to add purple features to the gray features. These are then used as input to LAYER\_1 which performs a non-linear transformation to also add orange features to the gray and purple ones. And so on until the final output for this 3 layer denseblock is a concatenation of gray, purple, orange and green features. So, in a dense block, each layer adds some features on top of the existing feature maps. Therefore, as you can see the size of the feature map grows after a pass through each dense layer and the new features are concatenated to the existing features. One can think of the features as a global state of the network and each layer adds K features on top to the global state. This parameter K is referred to as growth rate of the network. DenseNet Architecture as a collection of DenseBlocks We already know by now from fig-4, that DenseNets are divided into multiple DenseBlocks. The various architectures of DenseNets have been summarized in the paper. Each architecture consists of four DenseBlocks with varying number of layers. For example, the DenseNet-121 has [6,12,24,16] layers in the four dense blocks whereas DenseNet-169 has [6, 12, 32, 32] layers. We can see that the first part of the DenseNet architecture consists of a 7x7 stride 2 Conv Layer followed by a 3x3 stride-2 MaxPooling layer. And the fourth dense block is followed by a Classification Layer that accepts the feature maps of all layers of the network to perform the classification. Also, the convolution operations inside each of the architectures are the Bottle Neck layers. What this means is that the 1x1 conv reduces the number of channels in the input and 3x3 conv performs the convolution operation on the transformed version of the input with reduced number of channels rather than the input. Bottleneck Layers By now, we know that each layer produces K feature maps which are then concatenated to previous feature maps. Therefore, the number of inputs are quite high especially for later layers in the network. This has huge computational requirements and to make it more efficient, the authors decided to utilize Bottleneck layers. From the paper: 1×1 convolution can be introduced as bottleneck layer before each 3×3 convolution to reduce the number of input feature-maps, and thus to improve computational efficiency. In our experiments, we let each 1×1 convolution produce 4k feature-maps. We know K refers to the growth rate, so what the authors have finalized on is for 1x1 conv to first produce 4*K feature maps and then perform 3x3 conv on these 4*k size feature maps. DenseNet Implementation We are now ready and have all the building blocks to implement DenseNet in PyTorch. DenseLayer Implementation The first thing we need is to implement the dense layer inside a dense block. class \_DenseLayer(nn.Module): def \_\_init\_\_(self, num\_input\_features, growth\_rate, bn\_size, drop\_rate, memory\_efficient=False): super(\_DenseLayer, self).\_\_init\_\_() self.add\_module('norm1', nn.BatchNorm2d(num\_input\_features)), self.add\_module('relu1', nn.ReLU(inplace=True)), self.add\_module('conv1', nn.Conv2d(num\_input\_features, bn\_size * growth\_rate, kernel\_size=1, stride=1, bias=False)), self.add\_module('norm2', nn.BatchNorm2d(bn\_size * growth\_rate)), self.add\_module('relu2', nn.ReLU(inplace=True)), self.add\_module('conv2', nn.Conv2d(bn\_size * growth\_rate, growth\_rate, kernel\_size=3, stride=1, padding=1, bias=False)), self.drop\_rate = float(drop\_rate) self.memory\_efficient = memory\_efficient def bn\_function(self, inputs): "Bottleneck function" \# type: (List[Tensor]) -{\textgreater} Tensor concated\_features = torch.cat(inputs, 1) bottleneck\_output = self.conv1(self.relu1(self.norm1(concated\_features))) \# noqa: T484 return bottleneck\_output def forward(self, input): \# noqa: F811 if isinstance(input, Tensor): prev\_features = [input] else: prev\_features = input bottleneck\_output = self.bn\_function(prev\_features) new\_features = self.conv2(self.relu2(self.norm2(bottleneck\_output))) if self.drop\_rate {\textgreater} 0: new\_features = F.dropout(new\_features, p=self.drop\_rate, training=self.training) return new\_features A DenseLayer accepts an input, concatenates the input together and performs bn\_function on these feature maps to get bottleneck\_output. This is done for computational efficiency. Finally, the convolution operation is performed to get new\_features which are of size K or growth\_rate. It should now be easy to map the above implementation with fig-5 shown below for reference again: Let’s say the above is an implementation of LAYER\_2. First, LAYER\_2 accepts the gray, purple, orange feature maps and concatenates them. Next, the LAYER\_2 performs a bottleneck operation to create bottleneck\_output for computational efficiency. Finally, the layer performs the HL operation as in eq-2 to generate new\_features. These new\_features are the green features as in fig-5. Great! So far we have successfully implemented Transition and Dense layers. DenseBlock Implementation Now, we are ready to implement the DenseBlock which consists of multiple such DenseLayers. class \_DenseBlock(nn.ModuleDict): \_version = 2 def \_\_init\_\_(self, num\_layers, num\_input\_features, bn\_size, growth\_rate, drop\_rate, memory\_efficient=False): super(\_DenseBlock, self).\_\_init\_\_() for i in range(num\_layers): layer = \_DenseLayer( num\_input\_features + i * growth\_rate, growth\_rate=growth\_rate, bn\_size=bn\_size, drop\_rate=drop\_rate, memory\_efficient=memory\_efficient, ) self.add\_module('denselayer\%d' \% (i + 1), layer) def forward(self, init\_features): features = [init\_features] for name, layer in self.items(): new\_features = layer(features) features.append(new\_features) return torch.cat(features, 1) Let’s map the implementation of this DenseBlock with fig-5 again. Let’s say we pass the number of layers num\_layers as 3 to create fig-5 block. In this case, let’s imagine that the num\_input\_features in gray in the figure is 64. We already know that the authors choose the bottleneck size bn\_size for 1x1 conv to be 4. Let’s consider the growth\_rate is 32 (same for all networks as in the paper). Great, so the first layer LAYER\_0 accepts 64 num\_input\_features and outputs extra 32 features. Excellent. Now, LAYER\_1 accepts the 96 features num\_input\_features + 1 * growth rate and outputs extra 32 features again. Finally, LAYER\_2 accepts 128 features num\_input\_features + 2 * growth rate and adds the 32 green features on top with are then concatenated to existing features and returned by the DenseBlock. At this stage, it should be really easy for you to map the implementation of dense block with fig-5. DenseNet Architecture Implementation Finally, we are now ready to implement the DenseNet architecture as we have already implemented the DenseLayer and DenseBlock. class DenseNet(nn.Module): def \_\_init\_\_(self, growth\_rate=32, block\_config=(6, 12, 24, 16), num\_init\_features=64, bn\_size=4, drop\_rate=0, num\_classes=1000, memory\_efficient=False): super(DenseNet, self).\_\_init\_\_() \# Convolution and pooling part from table-1 self.features = nn.Sequential(OrderedDict([ ('conv0', nn.Conv2d(3, num\_init\_features, kernel\_size=7, stride=2, padding=3, bias=False)), ('norm0', nn.BatchNorm2d(num\_init\_features)), ('relu0', nn.ReLU(inplace=True)), ('pool0', nn.MaxPool2d(kernel\_size=3, stride=2, padding=1)), ])) \# Add multiple denseblocks based on config \# for densenet-121 config: [6,12,24,16] num\_features = num\_init\_features for i, num\_layers in enumerate(block\_config): block = \_DenseBlock( num\_layers=num\_layers, num\_input\_features=num\_features, bn\_size=bn\_size, growth\_rate=growth\_rate, drop\_rate=drop\_rate, memory\_efficient=memory\_efficient ) self.features.add\_module('denseblock\%d' \% (i + 1), block) num\_features = num\_features + num\_layers * growth\_rate if i != len(block\_config) - 1: \# add transition layer between denseblocks to \# downsample trans = \_Transition(num\_input\_features=num\_features, num\_output\_features=num\_features // 2) self.features.add\_module('transition\%d' \% (i + 1), trans) num\_features = num\_features // 2 \# Final batch norm self.features.add\_module('norm5', nn.BatchNorm2d(num\_features)) \# Linear layer self.classifier = nn.Linear(num\_features, num\_classes) \# Official init from torch repo. for m in self.modules(): if isinstance(m, nn.Conv2d): nn.init.kaiming\_normal\_(m.weight) elif isinstance(m, nn.BatchNorm2d): nn.init.constant\_(m.weight, 1) nn.init.constant\_(m.bias, 0) elif isinstance(m, nn.Linear): nn.init.constant\_(m.bias, 0) def forward(self, x): features = self.features(x) out = F.relu(features, inplace=True) out = F.adaptive\_avg\_pool2d(out, (1, 1)) out = torch.flatten(out, 1) out = self.classifier(out) return out Let’s use the above implementation to create densenet-121 architecture. def \_densenet(arch, growth\_rate, block\_config, num\_init\_features, pretrained, progress, **kwargs): model = DenseNet(growth\_rate, block\_config, num\_init\_features, **kwargs) return model def densenet121(pretrained=False, progress=True, **kwargs): return \_densenet('densenet121', 32, (6, 12, 24, 16), 64, pretrained, progress, **kwargs) Here’s what happens. First, we initialize the stem of the DenseNet architecture - this is the convolution and pooling part from table-1. This part of the code does that: self.features = nn.Sequential(OrderedDict([ ('conv0', nn.Conv2d(3, num\_init\_features, kernel\_size=7, stride=2, padding=3, bias=False)), ('norm0', nn.BatchNorm2d(num\_init\_features)), ('relu0', nn.ReLU(inplace=True)), ('pool0', nn.MaxPool2d(kernel\_size=3, stride=2, padding=1)), ])) Next, based on the config, we create a DenseBlock based on the number of layers in the config. This part of the code does this: for i, num\_layers in enumerate(block\_config): block = \_DenseBlock( num\_layers=num\_layers, num\_input\_features=num\_features, bn\_size=bn\_size, growth\_rate=growth\_rate, drop\_rate=drop\_rate, memory\_efficient=memory\_efficient ) self.features.add\_module('denseblock\%d' \% (i + 1), block) Finally, we add Transition Layers between DenseBlocks. if i != len(block\_config) - 1: \# add transition layer between denseblocks to \# downsample trans = \_Transition(num\_input\_features=num\_features, num\_output\_features=num\_features // 2) self.features.add\_module('transition\%d' \% (i + 1), trans) num\_features = num\_features // 2 And that’s all the magic behind DenseNets! Conclusion Congratulations! Today, together, we successfully understood what DenseNets are and also understood the torchvision implementation of DenseNets. I hope that by now you have a very thorough understanding of the DenseNet architecture. As always, constructive feedback is always welcome at @amaarora. Also, feel free to subscribe to my blog here to receive regular updates regarding new blog posts. Thanks for reading! Credits All code implementations have been directly copied from torchvision.},
	language = {en},
	urldate = {2022-01-16},
	journal = {Committed towards better future},
	month = aug,
	year = {2020},
}

@misc{ruiz_understanding_2018,
	title = {Understanding and visualizing {DenseNets}},
	url = {https://towardsdatascience.com/understanding-and-visualizing-densenets-7f688092391a},
	abstract = {This post be found in PDF here.},
	language = {en},
	urldate = {2022-01-13},
	journal = {Medium},
	author = {Ruiz, Pablo},
	month = oct,
	year = {2018},
}

@article{dumoulin_guide_2018,
	title = {A guide to convolution arithmetic for deep learning},
	url = {http://arxiv.org/abs/1603.07285},
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	urldate = {2022-01-08},
	journal = {arXiv:1603.07285 [cs, stat]},
	author = {Dumoulin, Vincent and Visin, Francesco},
	month = jan,
	year = {2018},
	note = {arXiv: 1603.07285},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@inproceedings{lee_fine-grained_2019,
	title = {Fine-{Grained} {Plant} {Identification} using wide and deep learning model},
	url = {https://ieeexplore-ieee-org.ez-proxy.brooklyn.cuny.edu/document/8669407},
	doi = {10.1109/PlatCon.2019.8669407},
	abstract = {In recent years, with the evolution of deep learning technology, the performance of plant image recognition has improved remarkably. In this paper, we propose a model to address the fine-grained plant image classification task by using the wide and deep learning framework which combines a linear model and a deep learning model. Proposed method sums the result of the wide and deep learning model using a logistic function so that discrete features can be considered simultaneously with continuous image content. Our works used metadata such as the date of flowering and locational information for the wide model. Our experiment shows that the proposed method gives better performance than a baseline method.},
	booktitle = {2019 {International} {Conference} on {Platform} {Technology} and {Service} ({PlatCon})},
	author = {Lee, Jun Woo and Chan Yoon, Yeo},
	month = jan,
	year = {2019},
	keywords = {Deep learning, Feature extraction, Image classification, Image color analysis, Metadata, Predictive models, Task analysis, deep neural network, fine-grained image classification, plant image classification},
	pages = {1--5},
}

@inproceedings{du_prediction_2019,
	title = {Prediction of pregnancy diabetes based on machine learning},
	abstract = {Gestational diabetes (GDM) refers to the normal metabolism of glucose before pregnancy and the occurrence of diabetes during pregnancy. This disease is a serious threat to the health of this pregnant woman and infant, so it is important to accurately predict whether the target is a gestational diabetes patient based on various indicators. Based on the measured data of the hospital, this paper uses decision tree, logistic regression and DenseNet to predict the target when the disease is sick or to be sick in the future, and discuss their prediction accuracy separately, which can help doctors make rapid diagnosis and make timely prevention. In the end, it was found that the DenseNet model can better predict whether the target is gestational diabetes or not, and the model flexibility is better.},
	booktitle = {{BIBE} 2019; {The} {Third} {International} {Conference} on {Biological} {Information} and {Biomedical} {Engineering}},
	author = {Du, Fan and Zhong, Weiyang and Wu, Wei and Peng, Danhong and Xu, Tian and Wang, Jun and Wang, Gongdao and Hou, Fengzhen},
	month = jun,
	year = {2019},
	pages = {1--6},
}

@inproceedings{alagoz_modeling_2017,
	title = {Modeling a {Classifier} for {Solving} {Safety}-{Critical} {Binary} {Classification} {Tasks}},
	doi = {10.1109/ICMLA.2017.00-38},
	abstract = {This paper introduces a novel machine learning approach for performing binary decision-making tasks under uncertainty. Reducing the regression test effort of safety-critical black box systems is a safety-critical task as system failures would remain undetected if corresponding failing test cases are not executed. The uncertainty of potentially undetected system failures persists due to the lack of implementation knowledge of black-box systems. We refer to executing test cases as a costly labeling process due to required special test equipment and testing time. However, we model a binary classifier for selecting test cases. Accordingly, only fault revealing test cases should be selected and thus executed in order to reduce the overall cost of the regression test effort. On the one side, the classifier's specificity has to be maximized. On the other side, the classifier's sensitivity has to meet a specific quality-level since the number of undetected system failures should be limited. We will show in an industrial case study the benefits of our classifier where we reduce the regression test effort of safety-critical systems. The experimental results indicate that our implemented classifier outperforms other machine learning approaches in terms of sensitivity.},
	booktitle = {2017 16th {IEEE} {International} {Conference} on {Machine} {Learning} and {Applications} ({ICMLA})},
	author = {Alagoz, Ibrahim and Hoiss, Thomas and German, Reinhard},
	month = dec,
	year = {2017},
	keywords = {Black Box System, Learning systems, Linear Classifier, Optimization, Regression, Reliability, Safety, Safety Critical, Selection, Sensitivity, Test, Testing},
	pages = {914--919},
}

@book{raff_inside_2021,
	address = {Shelter Island, New York},
	title = {Inside {Deep} {Learning}: {Math}, {Algorithms}, {Models}},
	language = {English},
	publisher = {Manning Publications Co.},
	author = {Raff, Edward},
	year = {2021},
}

@misc{lodaya_timeseries_2021,
	title = {Timeseries clustering},
	copyright = {GPL-3.0},
	url = {https://github.com/tejaslodaya/timeseries-clustering-vae},
	abstract = {Variational Recurrent Autoencoder for timeseries clustering in pytorch},
	urldate = {2021-10-27},
	author = {Lodaya, Tejas},
	month = oct,
	year = {2021},
	note = {original-date: 2018-08-03T10:06:01Z},
	keywords = {autoencoder, clustering, timeseries},
}

@inproceedings{shao_controlvae_2020,
	title = {{ControlVAE}: {Controllable} {Variational} {Autoencoder}},
	shorttitle = {{ControlVAE}},
	url = {https://proceedings.mlr.press/v119/shao20b.html},
	abstract = {Variational Autoencoders (VAE) and their variants have been widely used in a variety of applications, such as dialog generation, image generation and disentangled representation learning. However, the existing VAE models may suffer from KL vanishing in language modeling and low reconstruction quality for disentangling. To address these issues, we propose a novel controllable variational autoencoder framework, ControlVAE, that combines a controller, inspired by automatic control theory, with the basic VAE to improve the performance of resulting generative models. Specifically, we design a new non-linear PI controller, a variant of the proportional-integral-derivative (PID) control, to automatically tune the hyperparameter (weight) added in the VAE objective using the output KL-divergence as feedback during model training. The framework is evaluated using three applications; namely, language modeling, disentangled representation learning, and image generation. The results show that ControlVAE can achieve much better reconstruction quality than the competitive methods for the comparable disentanglement performance. For language modeling, it not only averts the KL-vanishing, but also improves the diversity of generated text. Finally, we also demonstrate that ControlVAE improves the reconstruction quality for image generation compared to the original VAE.},
	language = {en},
	urldate = {2021-10-27},
	booktitle = {Proceedings of the 37th {International} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Shao, Huajie and Yao, Shuochao and Sun, Dachun and Zhang, Aston and Liu, Shengzhong and Liu, Dongxin and Wang, Jun and Abdelzaher, Tarek},
	month = nov,
	year = {2020},
	note = {ISSN: 2640-3498},
	pages = {8655--8664},
}

@misc{noauthor_annotated_nodate,
	title = {The {Annotated} {Encoder} {Decoder}},
	url = {https://bastings.github.io/annotated_encoder_decoder/},
	abstract = {A PyTorch tutorial implementing Bahdanau et al. (2015)},
	language = {en-US},
	urldate = {2021-10-26},
	journal = {The Annotated Encoder Decoder},
}

@article{cowton_combined_2018,
	title = {A {Combined} {Deep} {Learning} {GRU}-{Autoencoder} for the {Early} {Detection} of {Respiratory} {Disease} in {Pigs} {Using} {Multiple} {Environmental} {Sensors}},
	volume = {18},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1424-8220/18/8/2521},
	doi = {10.3390/s18082521},
	abstract = {We designed and evaluated an assumption-free, deep learning-based methodology for animal health monitoring, specifically for the early detection of respiratory disease in growing pigs based on environmental sensor data. Two recurrent neural networks (RNNs), each comprising gated recurrent units (GRUs), were used to create an autoencoder (GRU-AE) into which environmental data, collected from a variety of sensors, was processed to detect anomalies. An autoencoder is a type of network trained to reconstruct the patterns it is fed as input. By training the GRU-AE using environmental data that did not lead to an occurrence of respiratory disease, data that did not fit the pattern of \&ldquo;healthy environmental data\&rdquo; had a greater reconstruction error. All reconstruction errors were labelled as either normal or anomalous using threshold-based anomaly detection optimised with particle swarm optimisation (PSO), from which alerts are raised. The results from the GRU-AE method outperformed state-of-the-art techniques, raising alerts when such predictions deviated from the actual observations. The results show that a change in the environment can result in occurrences of pigs showing symptoms of respiratory disease within 1\&ndash;7 days, meaning that there is a period of time during which their keepers can act to mitigate the negative effect of respiratory diseases, such as porcine reproductive and respiratory syndrome (PRRS), a common and destructive disease endemic in pigs.},
	language = {en},
	number = {8},
	urldate = {2021-10-26},
	journal = {Sensors},
	author = {Cowton, Jake and Kyriazakis, Ilias and Plötz, Thomas and Bacardit, Jaume},
	month = aug,
	year = {2018},
	note = {Number: 8
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {GRU, anomaly detection, deep learning, disease, health, pig, sensors},
	pages = {2521},
}

@misc{noauthor_gated_2019,
	title = {Gated {Recurrent} {Unit} ({GRU}) {With} {PyTorch}},
	url = {https://blog.floydhub.com/gru-with-pytorch/},
	abstract = {The Gated Recurrent Unit (GRU) is the newer version of the more popular LSTM. Let's unveil this network and explore the differences between these 2 siblings.},
	language = {en},
	urldate = {2021-10-22},
	journal = {FloydHub Blog},
	month = jul,
	year = {2019},
}

@article{trinh_detecting_2019,
	title = {Detecting {Mobile} {Traffic} {Anomalies} {Through} {Physical} {Control} {Channel} {Fingerprinting}: {A} {Deep} {Semi}-{Supervised} {Approach}},
	volume = {7},
	issn = {2169-3536},
	shorttitle = {Detecting {Mobile} {Traffic} {Anomalies} {Through} {Physical} {Control} {Channel} {Fingerprinting}},
	doi = {10.1109/ACCESS.2019.2947742},
	abstract = {Among the smart capabilities promised by the next generation cellular networks (5G and beyond), it is fundamental that potential network anomalies are detected and timely treated to avoid critical issues concerning network performance, security, public safety. In this paper, we propose a comprehensive framework for detecting network anomalies using mobile traffic data: collecting data from the LTE Physical Downlink Control Channel (PDCCH) of different eNodeBs, we implement deep learning algorithms in a semi-supervised way to detect potential traffic anomalies that are generated, for example, by unexpected crowd gathering. With respect to other types of mobile dataset, using LTE PDCCH information, we are able to obtain fine-grained and high-resolution data for the users that are connected to the LTE eNodeB. Through a semi-supervised approach, algorithms are trained to detect anomalies using only one class of traffic samples. We design two algorithms based on stacked-LSTM Neural Networks: 1) LSTM Autoencoder (LSTM-AE), in which the objective is to reconstruct the traffic samples 2) LSTM traffic predictor (LSTM-PRED), where the goal is to predict the traffic in the next time-instants, based on historical data. In both cases, we analyze the reconstruction (or prediction) error to assess if the mobile traffic presents anomalies or not. Using the F1-score as metric, we demonstrate that the proposed methods are able to identify the anomalous traffic periods, beating a benchmark that comprises different state-of-the-art algorithms for anomaly detection.},
	journal = {IEEE Access},
	author = {Trinh, Hoang Duy and Zeydan, Engin and Giupponi, Lorenza and Dini, Paolo},
	year = {2019},
	note = {Conference Name: IEEE Access},
	keywords = {5G, Anomaly detection, Base stations, Deep learning, Feature extraction, LSTM autoencoder, LSTM networks, LTE, Long Term Evolution, PDCCH, Prediction algorithms, Urban areas, machine learning, mobile networks, semi-supervised learning, traffic prediction},
	pages = {152187--152201},
}

@article{zavrak_anomaly-based_2020,
	title = {Anomaly-{Based} {Intrusion} {Detection} {From} {Network} {Flow} {Features} {Using} {Variational} {Autoencoder}},
	volume = {8},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2020.3001350},
	abstract = {The rapid increase in network traffic has recently led to the importance of flow-based intrusion detection systems processing a small amount of traffic data. Furthermore, anomaly-based methods, which can identify unknown attacks are also integrated into these systems. In this study, the focus is concentrated on the detection of anomalous network traffic (or intrusions) from flow-based data using unsupervised deep learning methods with semi-supervised learning approach. More specifically, Autoencoder and Variational Autoencoder methods were employed to identify unknown attacks using flow features. In the experiments carried out, the flow-based features extracted out of network traffic data, including typical and different types of attacks, were used. The Receiver Operating Characteristics (ROC) and the area under ROC curve, resulting from these methods were calculated and compared with One-Class Support Vector Machine. The ROC curves were examined in detail to analyze the performance of the methods in various threshold values. The experimental results show that Variational Autoencoder performs, for the most part, better than Autoencoder and One-Class Support Vector Machine.},
	journal = {IEEE Access},
	author = {Zavrak, Sultan and İskefiyeli, Murat},
	year = {2020},
	note = {Conference Name: IEEE Access},
	keywords = {Anomaly detection, Computer hacking, Deep learning, Feature extraction, Flow anomaly detection, Intrusion detection, Support vector machines, Telecommunication traffic, deep learning, intrusion detection, semi-supervised learning, variational autoencoder},
	pages = {108346--108358},
}

@inproceedings{mehta_delight_2020,
	address = {Vienna, Austria},
	title = {{DeLighT}: {Deep} and {Light}-weight {Transformer}},
	shorttitle = {{DeLighT}},
	url = {https://openreview.net/forum?id=ujmgfuxSLrO},
	abstract = {We introduce a deep and light-weight transformer, DeLighT, that delivers similar or better performance than standard transformer-based models with significantly fewer parameters. DeLighT more...},
	language = {en},
	urldate = {2021-10-16},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Learning} {Representations}},
	author = {Mehta, Sachin and Ghazvininejad, Marjan and Iyer, Srinivasan and Zettlemoyer, Luke and Hajishirzi, Hannaneh},
	month = sep,
	year = {2020},
}

@article{gao_seqvae_2021,
	title = {{SeqVAE}: {Sequence} variational autoencoder with policy gradient},
	issn = {1573-7497},
	shorttitle = {{SeqVAE}},
	url = {https://doi.org/10.1007/s10489-021-02374-7},
	doi = {10.1007/s10489-021-02374-7},
	abstract = {In the paper, we propose a variant of Variational Autoencoder (VAE) for sequence generation task, called SeqVAE, which is a combination of recurrent VAE and policy gradient in reinforcement learning. The goal of SeqVAE is to reduce the deviation of the optimization goal of VAE, which we achieved by adding the policy-gradient loss to SeqVAE. In the paper, we give two ways to calculate the policy-gradient loss, one is from SeqGAN and the other is proposed by us. In the experiments on them, our proposed method is better than all baselines, and experiments show that SeqVAE can alleviate the “post-collapse” problem. Essentially, SeqVAE can be regarded as a combination of VAE and Generative Adversarial Net (GAN) and has better learning ability than the plain VAE because of the increased adversarial process. Finally, an application of our SeqVAE to music melody generation is available online12.},
	language = {en},
	urldate = {2021-10-04},
	journal = {Applied Intelligence},
	author = {Gao, Ting and Cui, Yidong and Ding, Fanyu},
	month = apr,
	year = {2021},
}

@inproceedings{gjorgiev_time_2020,
	address = {Cham},
	series = {Communications in {Computer} and {Information} {Science}},
	title = {Time {Series} {Anomaly} {Detection} with {Variational} {Autoencoder} {Using} {Mahalanobis} {Distance}},
	isbn = {978-3-030-62098-1},
	doi = {10.1007/978-3-030-62098-1_4},
	abstract = {Two themes have dominated the research on anomaly detection in time series data, one related to explorations of deep architectures for the task, and the other, equally important, the creation of large benchmark datasets. In line with the current trends, we have proposed several deep learning architectures based on Variational Autoencoders that have been evaluated for detecting cyber-attacks on water distribution system on the BATADAL challenge task and dataset. The second research aim of this study was to examine the impact of using Mahalanobis distance as a reconstruction error on the performance of the proposed models.},
	language = {en},
	booktitle = {{ICT} {Innovations} 2020. {Machine} {Learning} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Gjorgiev, Laze and Gievska, Sonja},
	editor = {Dimitrova, Vesna and Dimitrovski, Ivica},
	year = {2020},
	keywords = {Anomaly detection, Mahalanobis distance, Time series analysis, Variational autoencoder},
	pages = {42--55},
}

@inproceedings{wang_transvaenovel_2021,
	title = {{TransVae}:{A} {Novel} {Variational} {Sequence}-to-{Sequence} {Framework} for {Semi}-supervised {Learning} and {Diversity} {Improvement}},
	shorttitle = {{TransVae}},
	doi = {10.1109/IJCNN52387.2021.9533638},
	abstract = {Text generation tasks require that the generated text have certain diversity while ensuring the relevance. Traditional Seq2Seq models usually use cross entropy as the objective function. It demands the results keep strictly consistent with the ground truth texts, which easily leads to the lack of variability in generated texts. In this paper, we propose a novel framework, TransVAE, which applies Variational Auto-Encoder (VAE) to improve the Seq2Seq architecture. We design the Translator module to transform the latent variable spaces of origin input to target output, thus enhancing the diversity of generated texts and supporting semi-supervised learning. Moreover, we add attention and copy mechanisms to the TransVAE model to balance the relevance and diversity. Abundant experiments are carried out on three different string transduction tasks: dialogue generation, machine translation, and text summarization. The experiment results verify the effectiveness of our method.},
	booktitle = {2021 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Wang, Xinyi and Hu, Tianxiang and Ren, Xingzhang and Sun, Jinan and Liu, Kai and Zhang, Minghui},
	month = jul,
	year = {2021},
	note = {ISSN: 2161-4407},
	keywords = {Entropy, Gaussian distribution, Linear programming, Natural Language Processing, Natural languages, Neural networks, Semisupervised learning, Text Generation, Transforms, Variational Auto-Encoder},
	pages = {1--8},
}

@misc{alex_1-d_2020,
	title = {1-d {Convolutional} {Neural} {Networks} for {Time} {Series}: {Basic} {Intuition}},
	shorttitle = {1-d {Convolutional} {Neural} {Networks} for {Time} {Series}},
	url = {https://boostedml.com/2020/04/1-d-convolutional-neural-networks-for-time-series-basic-intuition.html},
	abstract = {In this post we describe the basics of 1-d convolutional neural networks, which can be...},
	language = {en-US},
	urldate = {2021-10-03},
	journal = {Boostedml},
	author = {{ALEX}},
	month = apr,
	year = {2020},
}

@article{srinivasamurthy_understanding_nodate,
	title = {Understanding {1D} {Convolutional} {Neural} {Networks} {Using} {Multiclass} {Time}-{Varying} {Signals}},
	language = {en},
	author = {Srinivasamurthy, Ravisutha Sakrepatna},
	pages = {99},
}

@misc{noauthor_file_nodate,
	title = {File {Finder} · matthewvowels1/{Awesome}-{VAEs}},
	url = {https://github.com/matthewvowels1/Awesome-VAEs},
	abstract = {A curated list of awesome work on VAEs, disentanglement, representation learning, and generative models. - File Finder · matthewvowels1/Awesome-VAEs},
	language = {en},
	urldate = {2021-10-03},
	journal = {GitHub},
}

@article{chien_hierarchical_2021,
	title = {Hierarchical and {Self}-{Attended} {Sequence} {Autoencoder}},
	issn = {1939-3539},
	doi = {10.1109/TPAMI.2021.3068187},
	abstract = {It is important and challenging to infer stochastic latent semantics for natural language applications. The difficulty in stochastic sequential learning is caused by the posterior collapse in variational inference. The input sequence is disregarded in the estimated latent variables. This paper proposes three components to tackle this difficulty and build the variational sequence autoencoder (VSAE) where sufficient latent information is learned for sophisticated sequence representation. First, the complementary encoders based on a long short-term memory (LSTM) and a pyramid bidirectional LSTM are merged to characterize global and structural dependencies of an input sequence, respectively. Second, a stochastic self attention mechanism is incorporated in a recurrent decoder. The latent information is attended to encourage the interaction between inference and generation in an encoder-decoder training procedure. Third, an autoregressive Gaussian prior of latent variable is used to preserve the information bound. Different variants of VSAE are proposed to mitigate the posterior collapse in sequence modeling. A series of experiments are conducted to demonstrate that the proposed individual and hybrid sequence autoencoders substantially improve the performance for variational sequential learning in language modeling and semantic understanding for document classification and summarization.},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Chien, Jen-Tzung and Wang, Chun-Wei},
	year = {2021},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Data models, Decoding, Natural languages, Recurrent neural networks, Semantics, Sequence generation, Stochastic processes, Training, hierarchical model, recurrent neural network, self attention, variational autoencoder},
	pages = {1--1},
}

@misc{mao_gated_nodate,
	title = {Gated {Linear} {Units} ({GLU}) and {Gated} {CNN}},
	url = {https://leimao.github.io/blog/Gated-Linear-Units/},
	abstract = {Hello Underworld.},
	language = {en},
	urldate = {2021-10-02},
	journal = {Lei Mao's Log Book},
	author = {Mao, Lei},
}

@article{cui_6gcvae_2020,
	title = {{6GCVAE}: {Gated} {Convolutional} {Variational} {Autoencoder} for {IPv6} {Target} {Generation}},
	volume = {12084},
	shorttitle = {{6GCVAE}},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7206168/},
	doi = {10.1007/978-3-030-47426-3_47},
	abstract = {IPv6 scanning has always been a challenge for researchers in the field of network measurement. Due to the considerable IPv6 address space, while recent network speed and computational power have been improved, using a brute-force approach to probe the entire network space of IPv6 is almost impossible. Systems are required an algorithmic approach to generate more possible active target candidate sets to probe. In this paper, we first try to use deep learning to design such IPv6 target generation algorithms. The model effectively learns the address structure by stacking the gated convolutional layer to construct Variational Autoencoder (VAE). We also introduce two address classification methods to improve the model effect of the target generation. Experiments indicate that our approach 6GCVAE outperformed the conventional VAE models and the state of the art target generation algorithm in two active address datasets.},
	urldate = {2021-10-02},
	journal = {Advances in Knowledge Discovery and Data Mining},
	author = {Cui, Tianyu and Gou, Gaopeng and Xiong, Gang},
	month = apr,
	year = {2020},
	pmid = {null},
	pmcid = {PMC7206168},
	pages = {609--622},
}

@article{wang_clvsa_2019,
	title = {{CLVSA}: {A} {Convolutional} {LSTM} {Based} {Variational} {Sequence}-to-{Sequence} {Model} with {Attention} for {Predicting} {Trends} of {Financial} {Markets}},
	shorttitle = {{CLVSA}},
	url = {http://arxiv.org/abs/2104.04041},
	doi = {10.24963/ijcai.2019/514},
	abstract = {Financial markets are a complex dynamical system. The complexity comes from the interaction between a market and its participants, in other words, the integrated outcome of activities of the entire participants determines the markets trend, while the markets trend affects activities of participants. These interwoven interactions make financial markets keep evolving. Inspired by stochastic recurrent models that successfully capture variability observed in natural sequential data such as speech and video, we propose CLVSA, a hybrid model that consists of stochastic recurrent networks, the sequence-to-sequence architecture, the self- and inter-attention mechanism, and convolutional LSTM units to capture variationally underlying features in raw financial trading data. Our model outperforms basic models, such as convolutional neural network, vanilla LSTM network, and sequence-to-sequence model with attention, based on backtesting results of six futures from January 2010 to December 2017. Our experimental results show that, by introducing an approximate posterior, CLVSA takes advantage of an extra regularizer based on the Kullback-Leibler divergence to prevent itself from overfitting traps.},
	urldate = {2021-10-02},
	journal = {Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence},
	author = {Wang, Jia and Sun, Tong and Liu, Benyuan and Cao, Yu and Zhu, Hongwei},
	month = aug,
	year = {2019},
	note = {arXiv: 2104.04041},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Statistical Finance},
	pages = {3705--3711},
}

@article{rakos_compression_2020,
	title = {Compression of {Vehicle} {Trajectories} with a {Variational} {Autoencoder}},
	volume = {10},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2076-3417/10/19/6739},
	doi = {10.3390/app10196739},
	abstract = {The perception and prediction of the surrounding vehicles\&rsquo; trajectories play a significant role in designing safe and optimal control strategies for connected and automated vehicles. The compression of trajectory data and the drivers\&rsquo; strategic behavior\&rsquo;s classification is essential to communicate in vehicular ad-hoc networks (VANETs). This paper presents a Variational Autoencoder (VAE) solution to solve the compression problem, and as an added benefit, it also provides classification information. The input is the time series of vehicle positions along actual real-world trajectories obtained from a dataset containing highway measurements, which also serves as the target. During training, the autoencoder learns to compress and decompress this data and produces a small, few element context vector that can represent vehicle behavior in a probabilistic manner. The experiments show how the size of this context vector affects the performance of the method. The method is compared to other approaches, namely, Bidirectional LSTM Autoencoder and Sparse Convolutional Autoencoder. According to the results, the Sparse Autoencoder fails to converge to the target for the specific tasks. The Bidirectional LSTM Autoencoder could provide the same performance as the VAE, though only with double context vector length, proving that the compression capability of the VAE is better. The Support Vector Machine method is used to prove that the context vector can be used for maneuver classification for lane changing behavior. The utilization of this method, considering neighboring vehicles, can be extended for maneuver prediction using a wider, more complex network structure.},
	language = {en},
	number = {19},
	urldate = {2021-10-02},
	journal = {Applied Sciences},
	author = {Rákos, Olivér and Aradi, Szilárd and Bécsi, Tamás and Szalay, Zsolt},
	month = jan,
	year = {2020},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {autoencoders, data compression, intelligent transportation systems, maneuver classification},
	pages = {6739},
}

@misc{jinwoo_torchcoder_2021,
	title = {{TorchCoder}},
	url = {https://github.com/hellojinwoo/TorchCoder},
	abstract = {PyTorch based autoencoder for sequential data, currently supporting only Long Short-Term Memory(LSTM) autoencoder.},
	urldate = {2021-10-02},
	author = {Jinwoo},
	month = sep,
	year = {2021},
	note = {original-date: 2020-01-22T05:49:15Z},
	keywords = {autoencoder, dimensionality-reduction, lstm, lstm-neural-network, recurrent-neural-network, representation-learning},
}

@techreport{noauthor_evaluation_2016,
	address = {Saint Louis, MS},
	type = {White paper},
	title = {An {Evaluation} of {Hierarchical} {Data} {Format} {Version} 5 ({HDF5}) as a {Storage} {Model} for {Archive} and {Delivery} of {Video} {Data}},
	url = {https://www.ncei.noaa.gov/sites/default/files/2020-04/HDF5_Video.pdf},
	urldate = {2021-09-15},
	institution = {General Dynamics Information Technology, Inc.},
	month = jun,
	year = {2016},
	pages = {10},
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	note = {Conference Name: Neural Computation},
	pages = {1735--1780},
}

@misc{noauthor_pytorch_nodate,
	title = {{PyTorch} {LSTM}: {The} {Definitive} {Guide} {\textbar} cnvrg.io},
	shorttitle = {{PyTorch} {LSTM}},
	url = {https://cnvrg.io/pytorch-lstm/},
	abstract = {In this article, you are going to learn about the special type of Neural Network known as “Long Short Term Memory” or LSTMs. This article is divided into 4},
	language = {en-US},
	urldate = {2021-09-27},
	note = {Section: Data Science},
}

@misc{noauthor_understanding_nodate,
	title = {Understanding {LSTM} {Networks} -- colah's blog},
	url = {https://colah.github.io/posts/2015-08-Understanding-LSTMs/},
	urldate = {2021-09-25},
}

@misc{noauthor_pytorch_nodate-1,
	title = {{PyTorch} {Lightning} — {PyTorch} {Lightning} 1.5.0dev documentation},
	url = {https://pytorch-lightning.readthedocs.io/en/latest/},
	urldate = {2021-09-18},
}

@misc{noauthor_learning_2016,
	title = {Learning from {Imbalanced} {Classes}},
	url = {https://www.svds.com/learning-imbalanced-classes/},
	abstract = {This post gives insight and concrete advice on how to tackle imbalanced data. If you deal with such problems and want practical advice, read on.},
	language = {en-US},
	urldate = {2021-09-16},
	journal = {Silicon Valley Data Science},
	month = aug,
	year = {2016},
	note = {Section: Uncategorized},
}

@inproceedings{folk_overview_2011,
	address = {New York, NY, USA},
	series = {{AD} '11},
	title = {An overview of the {HDF5} technology suite and its applications},
	isbn = {978-1-4503-0614-0},
	url = {http://doi.org/10.1145/1966895.1966900},
	doi = {10.1145/1966895.1966900},
	abstract = {In this paper, we give an overview of the HDF5 technology suite and some of its applications. We discuss the HDF5 data model, the HDF5 software architecture and some of its performance enhancing capabilities.},
	urldate = {2021-09-15},
	booktitle = {Proceedings of the {EDBT}/{ICDT} 2011 {Workshop} on {Array} {Databases}},
	publisher = {Association for Computing Machinery},
	author = {Folk, Mike and Heber, Gerd and Koziol, Quincey and Pourmal, Elena and Robinson, Dana},
	month = mar,
	year = {2011},
	keywords = {HDF5, data management, data models, databases},
	pages = {36--47},
}

@misc{shawn_p_duncan_censored_2022,
	title = {Replication Package for Network-based Internet Censorship Detection},
	copyright = {GPL 3.0},
	url = {https://github.com/FatherShawn/cp_learning},
	abstract = {Preprocessing and machine learning implementation for "Finding Latent Features in Internet Censorship Data"},
	author = {{Shawn P. Duncan}},
	month = may,
	year = {2022},
  publisher = {GitHub},
  journal = {GitHub repository},
}

@misc{noauthor_nlp_nodate,
	title = {{NLP} {From} {Scratch}: {Translation} with a {Sequence} to {Sequence} {Network} and {Attention}},
	url = {https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial},
	abstract = {This is the third and final tutorial on doing “NLP From Scratch”, where we write our own classes and functions to preprocess the data to do our NLP modeling tasks.},
	urldate = {2021-07-30},
	journal = {Pytorch Tutorials},
}

@misc{amirsina_torfi_sequence_nodate,
	title = {Sequence to {Sequence} from {Scratch}},
	url = {https://github.com/astorfi/sequence-to-sequence-from-scratch},
	abstract = {It tutorial has been provided for the developers/researchers who really want to start from scratch and learn everything spoon-by-spoon. The goal is to give as much detail as possible so the others do NOT have to spend the time to understand hidden and yet very important details.},
	author = {{Amirsina Torfi}},
}

@article{siavoshani_machine_2020,
	title = {Machine {Learning} {Interpretability} {Meets} {TLS} {Fingerprinting}},
	url = {http://arxiv.org/abs/2011.06304},
	abstract = {Protecting users' privacy over the Internet is of great importance. However, due to the increasing complexity of network protocols and components, it becomes harder and harder to maintain. Therefore, investigating and understanding how data is leaked from the information transport platform/protocols can lead us to a more secure environment. In this paper, we propose an iterative framework to find the most vulnerable information fields in a network protocol systematically. To this end, focusing on the Transport Layer Security (TLS) protocol, we perform different machine-learning-based fingerprinting attacks by collecting data from more than 70 domains (websites) to understand how and where this information leakage occurs in the TLS protocol. Then, by employing the interpretation techniques developed in the machine learning community, and using our framework, we find the most vulnerable information fields in the TLS protocol. Our findings demonstrate that the TLS handshake (which is mainly unencrypted), the TLS record length appears in the TLS application data header, and the initialization vector (IV) field are among the most critical leaker parts in this protocol, respectively.},
	urldate = {2021-07-18},
	journal = {arXiv:2011.06304 [cs]},
	author = {Siavoshani, Mahdi Jafari and Khajepour, Amir Hossein and Ziaei, Amirmohammad and Gatmiri, Amir Ali and Taheri, Ali},
	month = nov,
	year = {2020},
	note = {arXiv: 2011.06304},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Computer Science - Networking and Internet Architecture},
}

@article{hemalatha_efficient_2021,
	title = {An {Efficient} {DenseNet}-{Based} {Deep} {Learning} {Model} for {Malware} {Detection}},
	volume = {23},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/1099-4300/23/3/344},
	doi = {10.3390/e23030344},
	abstract = {Recently, there has been a huge rise in malware growth, which creates a significant security threat to organizations and individuals. Despite the incessant efforts of cybersecurity research to defend against malware threats, malware developers discover new ways to evade these defense techniques. Traditional static and dynamic analysis methods are ineffective in identifying new malware and pose high overhead in terms of memory and time. Typical machine learning approaches that train a classifier based on handcrafted features are also not sufficiently potent against these evasive techniques and require more efforts due to feature-engineering. Recent malware detectors indicate performance degradation due to class imbalance in malware datasets. To resolve these challenges, this work adopts a visualization-based method, where malware binaries are depicted as two-dimensional images and classified by a deep learning model. We propose an efficient malware detection system based on deep learning. The system uses a reweighted class-balanced loss function in the final classification layer of the DenseNet model to achieve significant performance improvements in classifying malware by handling imbalanced data issues. Comprehensive experiments performed on four benchmark malware datasets show that the proposed approach can detect new malware samples with higher accuracy (98.23\% for the Malimg dataset, 98.46\% for the BIG 2015 dataset, 98.21\% for the MaleVis dataset, and 89.48\% for the unseen Malicia dataset) and reduced false-positive rates when compared with conventional malware mitigation techniques while maintaining low computational time. The proposed malware detection solution is also reliable and effective against obfuscation attacks.},
	language = {en},
	number = {3},
	urldate = {2021-06-21},
	journal = {Entropy},
	author = {Hemalatha, Jeyaprakash and Roseline, S. Abijah and Geetha, Subbiah and Kadry, Seifedine and Damaševičius, Robertas},
	month = mar,
	year = {2021},
	keywords = {cybersecurity, deep learning, densely connected convolutional network, malware detection, malware visualization},
	pages = {344},
}

@inproceedings{lee_fine-grained_2019-1,
	title = {Fine-{Grained} {Plant} {Identification} using wide and deep learning model},
	url = {https://ieeexplore-ieee-org.ez-proxy.brooklyn.cuny.edu/document/8669407/},
	doi = {10.1109/PlatCon.2019.8669407},
	abstract = {In recent years, with the evolution of deep learning technology, the performance of plant image recognition has improved remarkably. In this paper, we propose a model to address the fine-grained plant image classification task by using the wide and deep learning framework which combines a linear model and a deep learning model. Proposed method sums the result of the wide and deep learning model using a logistic function so that discrete features can be considered simultaneously with continuous image content. Our works used metadata such as the date of flowering and locational information for the wide model. Our experiment shows that the proposed method gives better performance than a baseline method.},
	booktitle = {2019 {International} {Conference} on {Platform} {Technology} and {Service} ({PlatCon})},
	author = {Lee, Jun Woo and Chan Yoon, Yeo},
	month = jan,
	year = {2019},
	keywords = {Deep learning, Feature extraction, Image classification, Image color analysis, Metadata, Predictive models, Task analysis, deep neural network, fine-grained image classification, plant image classification},
	pages = {1--5},
}

@inproceedings{chung_semi-supervised_2020,
	title = {Semi-supervised {Training} for {Sequence}-to-{Sequence} {Speech} {Recognition} {Using} {Reinforcement} {Learning}},
	doi = {10.1109/IJCNN48605.2020.9207023},
	abstract = {This paper proposes a reinforcement learning based semi-supervised training approach for sequence-to-sequence automatic speech recognition (ASR) systems. Most recent semi-supervised training approaches are based on multi-loss functions such as cross-entropy loss for speech-to-text paired data and reconstruction loss for speech-text unpaired data.Although these approaches show promising results, some considerations still remain: (a) different loss functions are used for paired and unpaired data separately even though the purpose is classification accuracy improvement, and (b) several methods need auxiliary networks that increase the complexity of a semi-supervised training process.To address these issues, a reinforcement learning based approach is proposed. The proposed approach focuses on rewarding ASR to generate more correct sentences for both paired and unpaired speech data. The proposed approach is evaluated on the Wall Street Journal task domain. The experimental results show that the proposed method is effective by reducing the character error rate from 10.4\% to 8.7\%.},
	booktitle = {2020 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Chung, Hoon and Jeon, Hyeong-Bae and Park, Jeon Gue},
	month = jul,
	year = {2020},
	note = {ISSN: 2161-4407},
	keywords = {Data models, Decoding, Error analysis, Learning (artificial intelligence), Speech recognition, Task analysis, Training, automatic speech recognition, reinforcement learning, semi-supervised learning},
	pages = {1--6},
}

@article{ke_yan_unsupervised_2020,
	title = {Unsupervised learning for fault detection and diagnosis of air handling units},
	volume = {210},
	issn = {0378-7788},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0378778819320134},
	doi = {10.1016/j.enbuild.2019.109689},
	abstract = {Supervised learning techniques have witnessed significant successes in fault detection and diagnosis (FDD) for heating ventilation and air-conditionin…},
	language = {en},
	urldate = {2021-06-07},
	journal = {Energy and Buildings},
	author = {{Ke Yan} and {Jing Huang} and {Shen Wen} and {Zhiwei Ji}},
	month = mar,
	year = {2020},
	pages = {109689},
}

@article{cheng_wide_2016,
	title = {Wide \& {Deep} {Learning} for {Recommender} {Systems}},
	url = {http://arxiv.org/abs/1606.07792},
	abstract = {Generalized linear models with nonlinear feature transformations are widely used for large-scale regression and classification problems with sparse inputs. Memorization of feature interactions through a wide set of cross-product feature transformations are effective and interpretable, while generalization requires more feature engineering effort. With less feature engineering, deep neural networks can generalize better to unseen feature combinations through low-dimensional dense embeddings learned for the sparse features. However, deep neural networks with embeddings can over-generalize and recommend less relevant items when the user-item interactions are sparse and high-rank. In this paper, we present Wide \& Deep learning---jointly trained wide linear models and deep neural networks---to combine the benefits of memorization and generalization for recommender systems. We productionized and evaluated the system on Google Play, a commercial mobile app store with over one billion active users and over one million apps. Online experiment results show that Wide \& Deep significantly increased app acquisitions compared with wide-only and deep-only models. We have also open-sourced our implementation in TensorFlow.},
	urldate = {2021-06-07},
	journal = {arXiv:1606.07792 [cs, stat]},
	author = {Cheng, Heng-Tze and Koc, Levent and Harmsen, Jeremiah and Shaked, Tal and Chandra, Tushar and Aradhye, Hrishi and Anderson, Glen and Corrado, Greg and Chai, Wei and Ispir, Mustafa and Anil, Rohan and Haque, Zakaria and Hong, Lichan and Jain, Vihan and Liu, Xiaobing and Shah, Hemal},
	month = jun,
	year = {2016},
	note = {arXiv: 1606.07792},
	keywords = {Computer Science - Information Retrieval, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{vaswani_attention_2017,
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2021-06-07},
	journal = {arXiv:1706.03762 [cs]},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	note = {arXiv: 1706.03762},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}

@article{kang_network_2020,
	title = {Network {Anomaly} {Detection} {Technologies} {Using} {Unsupervised} {Learning} {AutoEncoders}},
	volume = {30},
	issn = {1598-3986},
	url = {https://www.koreascience.or.kr/article/JAKO202025356104838.page},
	doi = {10.13089/JKIISC.2020.30.4.617},
	abstract = {인터넷 컴퓨팅 환경의 변화, 새로운 서비스 출현, 그리고 지능화되어 가는 해커들의 다양한 공격으로 인한 규칙 기반 침입탐지시스템의 한계점을 극복하기 위해 기계학습 및 딥러닝 기술을 활용한 네트워크 이상 검출(NAD: Network Anomaly Detection)에 대한 관심이 집중되고 있다. NAD를 위한 대부분의 기존 기계학습 및 딥러닝 기술은 '정상'과 '공격'으로 레이블링된 훈련용 데이터 셋을 학습하는 지도학습 방법을 사용한다. 본 논문에서는 공격의 징후가 없는 일상의 네트워크에서 수집할 수 있는 레이블링이 필요 없는 데이터 셋을 이용하는 비지도학습 오토 엔코더(AE: AutoEncoder)를 활용한 NAD 적용 가능성을 제시한다. AE 성능을 검증하기 위해 NSL-KDD 훈련 및 시험 데이터 셋을 사용해 정확도, 정밀도, 재현율, f1-점수, 그리고 ROC AUC (Receiver Operating Characteristic Area Under Curve) 값을 보인다. 특히 이들 성능지표를 대상으로 AE의 층수, 규제 강도, 그리고 디노이징 효과 등을 분석하여 레퍼런스 모델을 제시하였다. AE의 훈련 데이터 셋에 대한 재생오류 82-th 백분위수를 기준 값으로 KDDTest+와 KDDTest-21 시험 데이터 셋에 대해 90.4\%와 89\% f1-점수를 각각 보였다. In order to overcome the limitations of the rule-based intrusion detection system due to changes in Internet computing environments, the emergence of new services, and creativity of attackers, network anomaly detection (NAD) using machine learning and deep learning technologies has received much attention. Most of these existing machine learning and deep learning technologies for NAD use supervised learning methods to learn a set of training data set labeled 'normal' and 'attack'. This paper presents the feasibility of the unsupervised learning AutoEncoder(AE) to NAD from data sets collecting of secured network traffic without labeled responses. To verify the performance of the proposed AE mode, we present the experimental results in terms of accuracy, precision, recall, f1-score, and ROC AUC value on the NSL-KDD training and test data sets. In particular, we model a reference AE through the deep analysis of diverse AEs varying hyper-parameters such as the number of layers as well as considering the regularization and denoising effects. The reference model shows the f1-scores 90.4\% and 89\% of binary classification on the KDDTest+ and KDDTest-21 test data sets based on the threshold of the 82-th percentile of the AE reconstruction error of the training data set.},
	language = {kor},
	number = {4},
	urldate = {2021-06-07},
	journal = {Journal of the Korea Institute of Information Security \& Cryptology},
	author = {Kang, Koohong},
	year = {2020},
	pages = {617--629},
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
}

@article{dumoulin_guide_2018-1,
	title = {A guide to convolution arithmetic for deep learning},
	url = {http://arxiv.org/abs/1603.07285},
	abstract = {We introduce a guide to help deep learning practitioners understand and manipulate convolutional neural network architectures. The guide clarifies the relationship between various properties (input shape, kernel shape, zero padding, strides and output shape) of convolutional, pooling and transposed convolutional layers, as well as the relationship between convolutional and transposed convolutional layers. Relationships are derived for various cases, and are illustrated in order to make them intuitive.},
	urldate = {2021-05-24},
	journal = {arXiv:1603.07285 [cs, stat]},
	author = {Dumoulin, Vincent and Visin, Francesco},
	month = jan,
	year = {2018},
	note = {arXiv: 1603.07285},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@incollection{roesler_data_2020,
	address = {Cham},
	title = {Data from {Multiple} {Web} {Sources}: {Crawling}, {Integrating}, {Preprocessing}, and {Designing} {Applications}},
	isbn = {978-3-030-35101-4 978-3-030-35102-1},
	shorttitle = {Data from {Multiple} {Web} {Sources}},
	url = {http://link.springer.com/10.1007/978-3-030-35102-1_8},
	language = {en},
	urldate = {2021-05-10},
	booktitle = {Special {Topics} in {Multimedia}, {IoT} and {Web} {Technologies}},
	publisher = {Springer International Publishing},
	author = {Batista, Natércia A. and Brandão, Michele A. and Pinheiro, Michele B. and Dalip, Daniel H. and Moro, Mirella M.},
	editor = {Roesler, Valter and Barrére, Eduardo and Willrich, Roberto},
	year = {2020},
	doi = {10.1007/978-3-030-35102-1_8},
	pages = {213--242},
}

@article{ruder_overview_2017,
	title = {An overview of gradient descent optimization algorithms},
	url = {http://arxiv.org/abs/1609.04747},
	abstract = {Gradient descent optimization algorithms, while increasingly popular, are often used as black-box optimizers, as practical explanations of their strengths and weaknesses are hard to come by. This article aims to provide the reader with intuitions with regard to the behaviour of different algorithms that will allow her to put them to use. In the course of this overview, we look at different variants of gradient descent, summarize challenges, introduce the most common optimization algorithms, review architectures in a parallel and distributed setting, and investigate additional strategies for optimizing gradient descent.},
	urldate = {2021-05-10},
	journal = {arXiv:1609.04747 [cs]},
	author = {Ruder, Sebastian},
	month = jun,
	year = {2017},
	note = {arXiv: 1609.04747},
	keywords = {Computer Science - Machine Learning},
}

@article{zotova_semi-automatic_2021,
	title = {Semi-automatic generation of multilingual datasets for stance detection in {Twitter}},
	volume = {170},
	issn = {09574174},
	url = {http://ez-proxy.brooklyn.cuny.edu:2048/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=aci&AN=148986708&site=ehost-live},
	doi = {10.1016/j.eswa.2020.114547},
	abstract = {• New method to semi-automatically build labeled stance detection datasets from Twitter. • Translation strategies outperform zero-shot approaches when data is translated to a high-resourced language. • User-based information helps to label individual tweets. • Our method is applicable to quickly and cheaply generate labeled Twitter-based data. Popular social media networks provide the perfect environment to study the opinions and attitudes expressed by users. While interactions in social media such as Twitter occur in many natural languages, research on stance detection (the position or attitude expressed with respect to a specific topic) within the Natural Language Processing field has largely been done for English. Although some efforts have recently been made to develop annotated data in other languages, there is a telling lack of resources to facilitate multilingual and crosslingual research on stance detection. This is partially due to the fact that manually annotating a corpus of social media texts is a difficult, slow and costly process. Furthermore, as stance is a highly domain- and topic-specific phenomenon, the need for annotated data is specially demanding. As a result, most of the manually labeled resources are hindered by their relatively small size and skewed class distribution. This paper presents a method to obtain multilingual datasets for stance detection in Twitter. Instead of manually annotating on a per tweet basis, we leverage user-based information to semi-automatically label large amounts of tweets. Empirical monolingual and cross-lingual experimentation and qualitative analysis show that our method helps to overcome the aforementioned difficulties to build large, balanced and multilingual labeled corpora. We believe that our method can be easily adapted to easily generate labeled social media data for other Natural Language Processing tasks and domains.},
	urldate = {2021-05-08},
	journal = {Expert Systems with Applications},
	author = {Zotova, Elena and Agerri, Rodrigo and Rigau, German},
	month = may,
	year = {2021},
	keywords = {Deep learning, Fake news, Multilingualism, Natural language processing, Natural languages, Skewness (Probability theory), Social interaction, Social media, Stance detection, Text categorization},
	pages = {N.PAG--N.PAG},
}

@inproceedings{spitkovsky_profiting_2010,
	address = {Uppsala, Sweden},
	title = {Profiting from {Mark}-{Up}: {Hyper}-{Text} {Annotations} for {Guided} {Parsing}},
	shorttitle = {Profiting from {Mark}-{Up}},
	url = {https://www.aclweb.org/anthology/P10-1130},
	urldate = {2021-05-08},
	booktitle = {Proceedings of the 48th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Spitkovsky, Valentin I. and Jurafsky, Daniel and Alshawi, Hiyan},
	month = jul,
	year = {2010},
	pages = {1278--1287},
}

@inproceedings{plank_what_2016,
	address = {Bochum, Germany},
	title = {What to do about non-standard (or non-canonical) language in {NLP}},
	url = {https://konvens.org/proceedings/2016/index.html},
	abstract = {Real world data differs radically from the benchmark corpora we use in natural language processing (NLP). As soon as we apply our technologies to the real world, performance drops. The reason for this problem is obvious: NLP models are trained on samples from a limited set of canonical varieties that are considered standard, most prominently English newswire. However, there are many dimensions, e.g., sociodemographics, language, genre, sentence type, etc. on which texts can differ from the standard. The solution is not obvious: we cannot control for all factors, and it is not clear how to best go beyond the current practice of training on homogeneous data from a single domain and language.},
	language = {en},
	urldate = {2021-05-08},
	booktitle = {Proceedings of the 13th {Conference} on {Natural} {Language} {Processing} ({KONVENS} 2016)},
	publisher = {German Society for Computational Linguistics \& Language Technology},
	author = {Plank, Barbara},
	year = {2016},
	pages = {8},
}

@inproceedings{camacho-collados_role_2018,
	address = {Brussels, Belgium},
	title = {On the {Role} of {Text} {Preprocessing} in {Neural} {Network} {Architectures}: {An} {Evaluation} {Study} on {Text} {Categorization} and {Sentiment} {Analysis}},
	shorttitle = {On the {Role} of {Text} {Preprocessing} in {Neural} {Network} {Architectures}},
	url = {http://aclweb.org/anthology/W18-5406},
	doi = {10.18653/v1/W18-5406},
	abstract = {Text preprocessing is often the ﬁrst step in the pipeline of a Natural Language Processing (NLP) system, with potential impact in its ﬁnal performance. Despite its importance, text preprocessing has not received much attention in the deep learning literature. In this paper we investigate the impact of simple text preprocessing decisions (particularly tokenizing, lemmatizing, lowercasing and multiword grouping) on the performance of a standard neural text classiﬁer. We perform an extensive evaluation on standard benchmarks from text categorization and sentiment analysis. While our experiments show that a simple tokenization of input text is generally adequate, they also highlight signiﬁcant degrees of variability across preprocessing techniques. This reveals the importance of paying attention to this usually-overlooked step in the pipeline, particularly when comparing different models. Finally, our evaluation provides insights into the best preprocessing practices for training word embeddings.},
	language = {en},
	urldate = {2021-05-08},
	booktitle = {Proceedings of the 2018 {EMNLP} {Workshop} {BlackboxNLP}: {Analyzing} and {Interpreting} {Neural} {Networks} for {NLP}},
	publisher = {Association for Computational Linguistics},
	author = {Camacho-Collados, Jose and Pilehvar, Mohammad Taher},
	year = {2018},
	pages = {40--46},
}

@misc{carlos_e_perez_pytorch_2017,
	type = {Medium},
	title = {{PyTorch}, {Dynamic} {Computational} {Graphs} and {Modular} {Deep} {Learning}},
	url = {https://medium.com/intuitionmachine/pytorch-dynamic-computational-graphs-and-modular-deep-learning-7e7f89f18d1},
	urldate = {2021-04-27},
	journal = {Intuition Machine},
	author = {{Carlos E. Perez}},
	month = jan,
	year = {2017},
}

@article{iandola_squeezenet_2016,
	title = {{SqueezeNet}: {AlexNet}-level accuracy with 50x fewer parameters and {\textless}0.{5MB} model size},
	shorttitle = {{SqueezeNet}},
	url = {http://arxiv.org/abs/1602.07360},
	abstract = {Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet},
	urldate = {2021-04-23},
	journal = {arXiv:1602.07360 [cs]},
	author = {Iandola, Forrest N. and Han, Song and Moskewicz, Matthew W. and Ashraf, Khalid and Dally, William J. and Keutzer, Kurt},
	month = nov,
	year = {2016},
	note = {arXiv: 1602.07360},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{janizek_adversarial_2020,
	title = {An {Adversarial} {Approach} for the {Robust} {Classification} of {Pneumonia} from {Chest} {Radiographs}},
	url = {http://arxiv.org/abs/2001.04051},
	abstract = {While deep learning has shown promise in the domain of disease classification from medical images, models based on state-of-the-art convolutional neural network architectures often exhibit performance loss due to dataset shift. Models trained using data from one hospital system achieve high predictive performance when tested on data from the same hospital, but perform significantly worse when they are tested in different hospital systems. Furthermore, even within a given hospital system, deep learning models have been shown to depend on hospital- and patient-level confounders rather than meaningful pathology to make classifications. In order for these models to be safely deployed, we would like to ensure that they do not use confounding variables to make their classification, and that they will work well even when tested on images from hospitals that were not included in the training data. We attempt to address this problem in the context of pneumonia classification from chest radiographs. We propose an approach based on adversarial optimization, which allows us to learn more robust models that do not depend on confounders. Specifically, we demonstrate improved out-of-hospital generalization performance of a pneumonia classifier by training a model that is invariant to the view position of chest radiographs (anterior-posterior vs. posterior-anterior). Our approach leads to better predictive performance on external hospital data than both a standard baseline and previously proposed methods to handle confounding, and also suggests a method for identifying models that may rely on confounders. Code available at https://github.com/suinleelab/cxr\_adv.},
	urldate = {2021-04-23},
	journal = {arXiv:2001.04051 [cs, eess, stat]},
	author = {Janizek, Joseph D. and Erion, Gabriel and DeGrave, Alex J. and Lee, Su-In},
	month = jan,
	year = {2020},
	note = {arXiv: 2001.04051},
	keywords = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing, Statistics - Machine Learning},
}

@inproceedings{dong_multi-modal_2020,
	address = {Online},
	title = {Multi-modal {Information} {Extraction} from {Text}, {Semi}-structured, and {Tabular} {Data} on the {Web}},
	url = {https://www.aclweb.org/anthology/2020.acl-tutorials.6},
	doi = {10.18653/v1/2020.acl-tutorials.6},
	abstract = {The World Wide Web contains vast quantities of textual information in several forms: unstructured text, template-based semi-structured webpages (which present data in key-value pairs and lists), and tables. Methods for extracting information from these sources and converting it to a structured form have been a target of research from the natural language processing (NLP), data mining, and database communities. While these researchers have largely separated extraction from web data into different problems based on the modality of the data, they have faced similar problems such as learning with limited labeled data, defining (or avoiding defining) ontologies, making use of prior knowledge, and scaling solutions to deal with the size of the Web. In this tutorial we take a holistic view toward information extraction, exploring the commonalities in the challenges and solutions developed to address these different forms of text. We will explore the approaches targeted at unstructured text that largely rely on learning syntactic or semantic textual patterns, approaches targeted at semi-structured documents that learn to identify structural patterns in the template, and approaches targeting web tables which rely heavily on entity linking and type information. While these different data modalities have largely been considered separately in the past, recent research has started taking a more inclusive approach toward textual extraction, in which the multiple signals offered by textual, layout, and visual clues are combined into a single extraction model made possible by new deep learning approaches. At the same time, trends within purely textual extraction have shifted toward full-document understanding rather than considering sentences as independent units. With this in mind, it is worth considering the information extraction problem as a whole to motivate solutions that harness textual semantics along with visual and semi-structured layout information. We will discuss these approaches and suggest avenues for future work.},
	urldate = {2021-04-22},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}: {Tutorial} {Abstracts}},
	publisher = {Association for Computational Linguistics},
	author = {Dong, Xin Luna and Hajishirzi, Hannaneh and Lockard, Colin and Shiralkar, Prashant},
	month = jul,
	year = {2020},
	pages = {23--26},
}

@article{ni_cross-lingual_2020,
	title = {Cross-{Lingual} {Relation} {Extraction} with {Transformers}},
	url = {http://arxiv.org/abs/2010.08652},
	abstract = {Relation extraction (RE) is one of the most important tasks in information extraction, as it provides essential information for many NLP applications. In this paper, we propose a cross-lingual RE approach that does not require any human annotation in a target language or any cross-lingual resources. Building upon unsupervised cross-lingual representation learning frameworks, we develop several deep Transformer based RE models with a novel encoding scheme that can effectively encode both entity location and entity type information. Our RE models, when trained with English data, outperform several deep neural network based English RE models. More importantly, our models can be applied to perform zero-shot cross-lingual RE, achieving the state-of-the-art cross-lingual RE performance on two datasets (68-89\% of the accuracy of the supervised target-language RE model). The high cross-lingual transfer efficiency without requiring additional training data or cross-lingual resources shows that our RE models are especially useful for low-resource languages.},
	urldate = {2021-04-22},
	journal = {arXiv:2010.08652 [cs]},
	author = {Ni, Jian and Moon, Taesun and Awasthy, Parul and Florian, Radu},
	month = oct,
	year = {2020},
	note = {arXiv: 2010.08652},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Information Retrieval, Computer Science - Machine Learning},
}

@misc{noauthor_xlm-r_nodate,
	title = {{XLM}-{R}: {State}-of-the-art cross-lingual understanding through self-supervision},
	shorttitle = {{XLM}-{R}},
	url = {https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/},
	abstract = {Facebook AI is open-sourcing XLM-R, a multilingual model that uses self-supervised training to achieve state-of-the-art performance on four cross-lingual understanding benchmarks.},
	language = {en},
	urldate = {2021-04-22},
}

@incollection{ott_fairseq_2019,
	title = {fairseq: {A} {Fast}, {Extensible} {Toolkit} for {Sequence} {Modeling}},
	isbn = {978-1-950737-16-1},
	shorttitle = {fairseq},
	url = {https://www.aclweb.org/anthology/N19-4009.pdf},
	abstract = {fairseq is an open-source sequence modeling toolkit that allows researchers and developers to train custom models for translation, summarization, language modeling, and other text generation tasks. The toolkit is based on PyTorch and supports distributed training across multiple GPUs and machines. We also support fast mixed-precision training and inference on modern GPUs. A demo video can be found at https://www.youtube.com/watch?v=OtgDdWtHvto},
	urldate = {2021-04-22},
	booktitle = {Proceedings of {NAACL}-{HLT} 2019: {Demonstrations}},
	author = {Ott, Myle and Edunov, Sergey and Baevski, Alexei and Fan, Angela and Gross, Sam and Ng, Nathan and Grangier, David and Auli, Michael},
	month = apr,
	year = {2019},
	note = {arXiv: 1904.01038},
	keywords = {Computer Science - Computation and Language},
	pages = {48--53},
}

@misc{noauthor_pytorchfairseq_2021,
	title = {pytorch/fairseq},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/pytorch/fairseq},
	abstract = {Facebook AI Research Sequence-to-Sequence Toolkit written in Python.},
	urldate = {2021-04-22},
	publisher = {pytorch},
	month = apr,
	year = {2021},
	note = {original-date: 2017-08-29T16:26:12Z},
	keywords = {artificial-intelligence, python, pytorch},
}

@inproceedings{abraham_fraudulent_2021,
	address = {Cham},
	title = {Fraudulent e-{Commerce} {Website} {Detection} {Model} {Using} {HTML}, {Text} and {Image} {Features}},
	volume = {1182},
	isbn = {978-3-030-49344-8 978-3-030-49345-5},
	url = {https://www-scopus-com.ez-proxy.brooklyn.cuny.edu/record/display.uri?eid=2-s2.0-85089715569&origin=resultslist&sort=plf-f&src=s&sid=6eb8bbc5e84668bf80581c848a38a4f4&sot=b&sdt=b&sl=96&s=TITLE-ABS-KEY%28Fraudulent+e-Commerce+Website+Detection+Model+Using+HTML%2c+Text+and+Image+Features%29&relpos=0&citeCnt=0&searchTerm=},
	language = {en},
	urldate = {2021-04-14},
	booktitle = {Proceedings of the 11th {International} {Conference} on {Soft} {Computing} and {Pattern} {Recognition} ({SoCPaR} 2019)},
	publisher = {Springer International Publishing},
	author = {Khoo, Eric and Zainal, Anazida and Ariffin, Nurfadilah and Kassim, Mohd Nizam and Maarof, Mohd Aizaini and Bakhtiari, Majid},
	editor = {Abraham, Ajith and Jabbar, M. A. and Tiwari, Sanju and Jesus, Isabel M. S.},
	year = {2021},
	doi = {10.1007/978-3-030-49345-5_19},
	pages = {177--186},
}

@inproceedings{wu_application_2018,
	address = {Yogyakarta Indonesia},
	title = {Application of machine learning to identify {Counterfeit} {Website}},
	isbn = {9781450364799},
	url = {https://dl.acm.org/doi/10.1145/3282373.3282407},
	doi = {10.1145/3282373.3282407},
	language = {en},
	urldate = {2021-04-14},
	booktitle = {Proceedings of the 20th {International} {Conference} on {Information} {Integration} and {Web}-based {Applications} \& {Services}},
	publisher = {ACM},
	author = {Wu, KuanTing and Chou, ShingHua and Chen, ShyhWei and Tsai, ChingTsorng and Yuan, ShyanMing},
	month = nov,
	year = {2018},
	pages = {321--324},
}

@article{alon_code2vec_2019,
	title = {code2vec: learning distributed representations of code},
	volume = {3},
	shorttitle = {code2vec},
	url = {https://doi.org/10.1145/3290353},
	doi = {10.1145/3290353},
	abstract = {We present a neural model for representing snippets of code as continuous distributed vectors (``code embeddings''). The main idea is to represent a code snippet as a single fixed-length code vector, which can be used to predict semantic properties of the snippet. To this end, code is first decomposed to a collection of paths in its abstract syntax tree. Then, the network learns the atomic representation of each path while simultaneously learning how to aggregate a set of them. We demonstrate the effectiveness of our approach by using it to predict a method's name from the vector representation of its body. We evaluate our approach by training a model on a dataset of 12M methods. We show that code vectors trained on this dataset can predict method names from files that were unobserved during training. Furthermore, we show that our model learns useful method name vectors that capture semantic similarities, combinations, and analogies. A comparison of our approach to previous techniques over the same dataset shows an improvement of more than 75\%, making it the first to successfully predict method names based on a large, cross-project corpus. Our trained model, visualizations and vector similarities are available as an interactive online demo at http://code2vec.org. The code, data and trained models are available at https://github.com/tech-srl/code2vec.},
	number = {POPL},
	urldate = {2021-04-14},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Alon, Uri and Zilberstein, Meital and Levy, Omer and Yahav, Eran},
	month = jan,
	year = {2019},
	keywords = {Big Code, Distributed Representations, Machine Learning},
	pages = {40:1--40:29},
}

@article{daghaghi_accelerating_2021,
	title = {Accelerating {SLIDE} {Deep} {Learning} on {Modern} {CPUs}: {Vectorization}, {Quantizations}, {Memory} {Optimizations}, and {More}},
	volume = {3},
	shorttitle = {Accelerating {SLIDE} {Deep} {Learning} on {Modern} {CPUs}},
	url = {https://proceedings.mlsys.org/paper/2021/hash/3636638817772e42b59d74cff571fbb3-Abstract.html},
	language = {en},
	urldate = {2021-04-12},
	journal = {Proceedings of Machine Learning and Systems},
	author = {Daghaghi, Shabnam and Meisburger, Nicholas and Zhao, Mengnan and Shrivastava, Anshumali},
	month = mar,
	year = {2021},
}

@misc{noauthor_62_nodate,
	title = {6.2. {Feature} extraction: {Customizing} the vectorizer classes},
	url = {https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes},
	abstract = {It is possible to customize the scikit learn vectorizer behavior by passing a callable to the vectorizer constructor Customizing the vectorizer can also be useful when handling Asian languages that do not use an explicit word separator such as whitespace.},
	urldate = {2021-04-11},
	journal = {scikit-learn: machine learning in Python},
}

@article{tahmasebi_social_2021,
	title = {Social movie recommender system based on deep autoencoder network using {Twitter} data},
	volume = {33},
	issn = {09410643},
	url = {http://ez-proxy.brooklyn.cuny.edu:2048/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=aci&AN=149024938&site=ehost-live},
	doi = {10.1007/s00521-020-05085-1},
	abstract = {Recommender systems attempt to provide effective suggestions to each user based on their interests and behaviors. These recommendations usually match the personal user preferences and assist them in the decision-making process. With the ever-expanding growth of information on the web, online education systems, e-commerce, and, eventually, the emergence of social networks, the necessity of developing such systems is unavoidable. Collaborative filtering and content-based filtering are among the most important techniques used in recommender systems. Meanwhile, with the significant advances in deep learning in recent years, the use of this technology has been widely observed in recommender systems. In this study, a hybrid social recommender system utilizing a deep autoencoder network is introduced. The proposed approach employs collaborative and content-based filtering, as well as users' social influence. The social influence of each user is calculated based on his/her social characteristics and behaviors on Twitter. For the evaluation purpose, the required datasets have been collected from MovieTweetings and Open Movie Database. The evaluation results show that the accuracy and effectiveness of the proposed approach have been improved compared to the other state-of-the-art methods.},
	number = {5},
	urldate = {2021-04-11},
	journal = {Neural Computing \& Applications},
	author = {Tahmasebi, Hossein and Ravanmehr, Reza and Mohamadrezaei, Rezvan},
	month = mar,
	year = {2021},
	keywords = {Collaborative filtering, Content-based filtering, Deep autoencoder network, Deep learning, Online education, Recommender systems, Social influence, Social networks, Social recommender system, Social systems},
	pages = {1607--1623},
}

@inproceedings{khattar_mvae_2019,
	address = {New York, NY, USA},
	series = {{WWW} '19},
	title = {{MVAE}: {Multimodal} {Variational} {Autoencoder} for {Fake} {News} {Detection}},
	isbn = {978-1-4503-6674-8},
	shorttitle = {{MVAE}},
	url = {http://doi.org/10.1145/3308558.3313552},
	doi = {10.1145/3308558.3313552},
	abstract = {In recent times, fake news and misinformation have had a disruptive and adverse impact on our lives. Given the prominence of microblogging networks as a source of news for most individuals, fake news now spreads at a faster pace and has a more profound impact than ever before. This makes detection of fake news an extremely important challenge. Fake news articles, just like genuine news articles, leverage multimedia content to manipulate user opinions but spread misinformation. A shortcoming of the current approaches for the detection of fake news is their inability to learn a shared representation of multimodal (textual + visual) information. We propose an end-to-end network, Multimodal Variational Autoencoder (MVAE), which uses a bimodal variational autoencoder coupled with a binary classifier for the task of fake news detection. The model consists of three main components, an encoder, a decoder and a fake news detector module. The variational autoencoder is capable of learning probabilistic latent variable models by optimizing a bound on the marginal likelihood of the observed data. The fake news detector then utilizes the multimodal representations obtained from the bimodal variational autoencoder to classify posts as fake or not. We conduct extensive experiments on two standard fake news datasets collected from popular microblogging websites: Weibo and Twitter. The experimental results show that across the two datasets, on average our model outperforms state-of-the-art methods by margins as large as {\textasciitilde} 6\% in accuracy and {\textasciitilde} 5\% in F1 scores.},
	urldate = {2021-04-11},
	booktitle = {The {World} {Wide} {Web} {Conference}},
	publisher = {Association for Computing Machinery},
	author = {Khattar, Dhruv and Goud, Jaipal Singh and Gupta, Manish and Varma, Vasudeva},
	month = may,
	year = {2019},
	keywords = {Fake news detection, microblogs, multimodal fusion, variational autoencoders},
	pages = {2915--2921},
}

@article{che_text_2020,
	title = {Text feature extraction based on stacked variational autoencoder},
	volume = {76},
	issn = {0141-9331},
	url = {https://www.sciencedirect.com/science/article/pii/S0141933120300879},
	doi = {10.1016/j.micpro.2020.103063},
	abstract = {This paper presents a text feature extraction model based on stacked variational autoencoder (SVAE). A noise reduction mechanism is designed for variational autoencoder in input layer of text feature extraction to reduce noise interference and improve robustness and feature discrimination of the model. Three kinds of deep SVAE network architectures are constructed to improve ability of representing learning to mine feature intension in depth. Experiments are carried out in several aspects, including comparative analysis of text feature extraction model, sparse performance, parameter selection and stacking. Results show that text feature extraction model of SVAE has good performance and effect. The highest accuracy of SVAE models of Fudan and Reuters datasets is 13.50\% and 8.96\% higher than that of PCA, respectively.},
	language = {en},
	urldate = {2021-04-11},
	journal = {Microprocessors and Microsystems},
	author = {Che, Lei and Yang, Xiaoping and Wang, Liang},
	month = jul,
	year = {2020},
	keywords = {Deep stack, Noise reduction, Text feature extraction, Variational autoencoder},
	pages = {103063},
}

@misc{blake-wilson_transport_2006,
	title = {Transport {Layer} {Security} ({TLS}) {Extensions}},
	shorttitle = {{RFC} 4366},
	url = {https://tools.ietf.org/html/rfc4366},
	abstract = {This document describes extensions that may be used to add functionality to Transport Layer Security (TLS).  It provides both generic extension mechanisms for the TLS handshake client and server hellos, and specific extensions using these generic mechanisms. The extensions may be used by TLS clients and servers.  The extensions are backwards compatible: communication is possible between TLS clients that support the extensions and TLS servers that do not support the extensions, and vice versa.},
	language = {en},
	urldate = {2021-04-07},
	publisher = {Internet Engineering Task Force},
	author = {Blake-Wilson, Simon and Nystrom, Magnus and Hopwood, David and Mikkelsen, Jan and Wright, Tim},
	month = apr,
	year = {2006},
}

@inproceedings{conneau_unsupervised_2020,
	address = {Online},
	title = {Unsupervised {Cross}-lingual {Representation} {Learning} at {Scale}},
	url = {https://www.aclweb.org/anthology/2020.acl-main.747},
	doi = {10.18653/v1/2020.acl-main.747},
	abstract = {This paper shows that pretraining multilingual language models at scale leads to significant performance gains for a wide range of cross-lingual transfer tasks. We train a Transformer-based masked language model on one hundred languages, using more than two terabytes of filtered CommonCrawl data. Our model, dubbed XLM-R, significantly outperforms multilingual BERT (mBERT) on a variety of cross-lingual benchmarks, including +14.6\% average accuracy on XNLI, +13\% average F1 score on MLQA, and +2.4\% F1 score on NER. XLM-R performs particularly well on low-resource languages, improving 15.7\% in XNLI accuracy for Swahili and 11.4\% for Urdu over previous XLM models. We also present a detailed empirical analysis of the key factors that are required to achieve these gains, including the trade-offs between (1) positive transfer and capacity dilution and (2) the performance of high and low resource languages at scale. Finally, we show, for the first time, the possibility of multilingual modeling without sacrificing per-language performance; XLM-R is very competitive with strong monolingual models on the GLUE and XNLI benchmarks. We will make our code and models publicly available.},
	urldate = {2021-04-04},
	booktitle = {Proceedings of the 58th {Annual} {Meeting} of the {Association} for {Computational} {Linguistics}},
	publisher = {Association for Computational Linguistics},
	author = {Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzmán, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
	month = jul,
	year = {2020},
	pages = {8440--8451},
}

@misc{noauthor_facebookresearchxlm_2021,
	title = {facebookresearch/{XLM}},
	copyright = {View license         ,                 View license},
	url = {https://github.com/facebookresearch/XLM},
	abstract = {PyTorch original implementation of Cross-lingual Language Model Pretraining.},
	urldate = {2021-04-03},
	publisher = {Facebook Research},
	month = apr,
	year = {2021},
	note = {original-date: 2019-02-02T00:15:33Z},
}

@article{pang_deep_2021,
	title = {Deep {Learning} for {Anomaly} {Detection}: {A} {Review}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Deep {Learning} for {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/2007.02500},
	doi = {10.1145/3439950},
	abstract = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This paper surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in three high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages and disadvantages, and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
	number = {2},
	urldate = {2021-03-30},
	journal = {ACM Computing Surveys},
	author = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton van den},
	month = mar,
	year = {2021},
	note = {arXiv: 2007.02500},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {1--38},
}

@inproceedings{vandersloot_quack_2018,
	address = {Baltimore, MD},
	title = {Quack: {Scalable} {Remote} {Measurement} of {Application}-{Layer} {Censorship}},
	isbn = {978-1-939133-04-5},
	shorttitle = {Quack},
	url = {https://www.usenix.org/conference/usenixsecurity18/presentation/vandersloot},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {27th \{{USENIX}\} {Security} {Symposium} (\{{USENIX}\} {Security} 18)},
	publisher = {USENIX Association},
	author = {VanderSloot, Benjamin and McDonald, Allison and Scott, Will and Halderman, J. Alex and Ensafi, Roya},
	year = {2018},
	pages = {187--202},
}

@inproceedings{raman_measuring_2020,
	address = {San Diego, CA},
	title = {Measuring the {Deployment} of {Network} {Censorship} {Filters} at {Global} {Scale}},
	isbn = {978-1-891562-61-7},
	url = {https://www.ndss-symposium.org/wp-content/uploads/2020/02/23099.pdf},
	doi = {10.14722/ndss.2020.23099},
	abstract = {Content ﬁltering technologies are often used for Internet censorship, but even as these technologies have become cheaper and easier to deploy, the censorship measurement community lacks a systematic approach to monitor their proliferation. Past research has focused on a handful of speciﬁc ﬁltering technologies, each of which required cumbersome manual detective work to identify. Researchers and policymakers require a more comprehensive picture of the state and evolution of censorship based on content ﬁltering in order to establish effective policies that protect Internet freedom.},
	language = {en},
	urldate = {2021-03-10},
	booktitle = {Proceedings 2020 {Network} and {Distributed} {System} {Security} {Symposium}},
	publisher = {Internet Society},
	author = {Raman, Ram Sundara and Stoll, Adrian and Dalek, Jakub and Ramesh, Reethika and Scott, Will and Ensafi, Roya},
	year = {2020},
	pages = {1--16},
}

@inproceedings{rajesh_recognizing_2013,
	address = {Enathi, India},
	title = {Recognizing the languages in {WebPages} — {A} framework for {NLP}},
	doi = {10.1109/ICCIC.2013.6724269},
	abstract = {In this paper we describe an experimental system using java programming language which demonstrates a variety of application level tradeoffs available to distributed NLP applications. In this paper, we proposed language identification system with N-gram-based matching for document retrieval. By using a well known N-gram based algorithm for automatic language identification, we construct a system that dynamically adds language labels for whole documents or text fragments.},
	booktitle = {2013 {IEEE} {International} {Conference} on {Computational} {Intelligence} and {Computing} {Research}},
	publisher = {Institute of Electrical and Electronics Engineers},
	author = {Rajesh, S. and Vandana, L. and Carie, C. A. and Marapelli, B.},
	month = dec,
	year = {2013},
	keywords = {Computational intelligence, Conferences, IRS, Internet, JAVA, NLP, Object Oriented, Search engines, Software, Training, Web pages, language Model},
	pages = {1--5},
}

@book{ferlitsch_deep_2021,
	address = {Shelter Island, NY},
	title = {Deep {Learning} {Design} {Patterns}},
	isbn = {978-1-61729-826-4},
	language = {English},
	publisher = {Manning Publications Co.},
	author = {Ferlitsch, Andrew},
	year = {2021},
	note = {OCLC: 1226480749},
}

@inproceedings{aizman_high_2019,
	address = {Los Angeles, CA},
	title = {High {Performance} {I}/{O} {For} {Large} {Scale} {Deep} {Learning}},
	doi = {10.1109/BigData47090.2019.9005703},
	abstract = {Training deep learning (DL) models on petascale datasets is essential for achieving competitive and state-of-the-art performance in applications such as speech, video analytics, and object recognition. However, existing distributed filesystems were not developed for the access patterns and usability requirements of DL jobs. In this paper, we describe AIStore, a highly scalable, easy-to-deploy storage system, and WebDataset, a standards-based storage format and library that permits efficient access to very large datasets. We compare system performance experimentally using image classification workloads and storing training data on a variety of backends, including local SSDs, single-node NFS, and two identical bare-metal clusters: HDFS and AIStore.},
	booktitle = {2019 {IEEE} {International} {Conference} on {Big} {Data} ({Big} {Data})},
	publisher = {Institute of Electrical and Electronics Engineers},
	author = {Aizman, A. and Maltby, G. and Breuel, T.},
	month = dec,
	year = {2019},
	keywords = {AIStore, Benchmark testing, DL jobs, Google, Libraries, Machine learning, Servers, Training, access patterns, deep learning, deep learning models, digital storage, distributed databases, distributed file systems, high performance I/O, image classification, image classification workloads, large scale deep learning, learning (artificial intelligence), metal clusters, object recognition, parallel processing, performance, petascale, scale-out, standards-based storage format, storage management, system performance, usability requirements, video analytics},
	pages = {5965--5967},
}

@misc{usenix_association_foci_2011,
	type = {Conference},
	title = {{FOCI} '11 {Call} for {Papers}},
	url = {https://www.usenix.org/legacy/events/foci11/cfp/},
	abstract = {The first USENIX Workshop on Free and Open Communications on the Internet (FOCI) seeks to bring together researchers and practitioners from both technology and policy who are working on policies or technologies to detect or circumvent practices that inhibit free and open communications on the Internet.},
	urldate = {2021-03-26},
	journal = {FOCI '11 Call for Papers},
	author = {{USENIX Association}},
	month = aug,
	year = {2011},
}

@techreport{zittrain_shifting_2017,
	address = {Rochester, NY},
	type = {Paper},
	title = {The {Shifting} {Landscape} of {Global} {Internet} {Censorship}},
	url = {https://papers.ssrn.com/abstract=2993485},
	abstract = {A sharp increase in web encryption and a worldwide shift away from standalone websites in favor of social media and online publishing platforms has altered the practice of state-level Internet censorship and in some cases led to broader crackdowns, the Internet Monitor project at the Berkman Klein Center for Internet \& Society at Harvard University finds. This study documents the practice of Internet censorship around the world through empirical testing in 45 countries of the availability of 2,046 of the world’s most-trafficked and influential websites, plus additional country-specific websites. The study finds evidence of filtering in 26 countries across four broad content themes: political, social, topics related to conflict and security, and Internet tools (a term that includes censorship circumvention tools as well as social media platforms). The majority of countries that censor content do so across all four themes, although the depth of the filtering varies.},
	language = {en},
	number = {ID 2993485},
	urldate = {2021-03-26},
	institution = {Social Science Research Network},
	author = {Zittrain, Jonathan L. and Faris, Robert and Noman, Helmi and Clark, Justin and Tilton, Casey and Morrison-Westphal, Ryan},
	month = jun,
	year = {2017},
	doi = {10.2139/ssrn.2993485},
	keywords = {Casey Tilton, Helmi Noman, Jonathan L. Zittrain, Justin Clark, Robert Faris, Ryan Morrison-Westphal, SSRN, The Shifting Landscape of Global Internet Censorship},
}

@article{aceto2018comprehensive,
  title={A comprehensive survey on {Internet} outages},
  author={Aceto, Giuseppe and Botta, Alessio and Marchetta, Pietro and Persico, Valerio and Pescap{\'e}, Antonio},
  journal={Journal of Network and Computer Applications},
  volume={113},
  pages={36--63},
  year={2018},
  publisher={Elsevier}
}

@article{aceto_internet_2015,
	title = {{Internet} Censorship detection: A survey},
	volume = {83},
	issn = {1389-1286},
	shorttitle = {Internet {Censorship} detection},
	url = {https://www.sciencedirect.com/science/article/pii/S1389128615000948},
	doi = {10.1016/j.comnet.2015.03.008},
	abstract = {Internet Censorship is a phenomenon that crosses several study fields, from computer networking and computer security to social sciences; together with censorship detection and censorship circumvention it has impact on Internet infrastructure, protocols and user behaviors. Detection of Internet Censorship is the basis for the study of this phenomenon, and recently it has received focus from a technical point of view. Due to the heterogeneity of study fields and approaches, the scientific corpus on these topics is still in need of an overall analysis, based on coherent framework and lexicon to describe the experimented approaches and findings. In this paper we present a survey on Internet Censorship detection. We propose a reference for censoring techniques and a characterization of censoring systems, with definitions of related concepts. Based on the censoring techniques investigated in literature, we propose an analysis and discussion of censorship detection techniques and architectures and we present a chronological synopsis of the literature adopting or introducing them. Then we collect, study, and discuss available tools and platforms for censorship detection, and propose a characterization scheme to analyze and compare them. Finally, we compare and discuss detection architectures, tools and platforms, and we use the results to infer current challenges and for proposing new directions in the field of censorship detection.},
	language = {en},
	urldate = {2021-03-26},
	journal = {Computer Networks},
	author = {Aceto, Giuseppe and Pescapé, Antonio},
	month = jun,
	year = {2015},
	keywords = {Communications surveillance, Internet Censorship, Network monitoring, Network security, Privacy},
	pages = {381--421},
}

@article{leberknight_taxonomy_2012,
	title = {A {Taxonomy} of {Censors} and {Anti}-{Censors}: {Part} {I}-{Impacts} of {Internet} {Censorship}},
	volume = {3},
	copyright = {Access limited to members},
	issn = {1947-9131},
	shorttitle = {A {Taxonomy} of {Censors} and {Anti}-{Censors}},
	url = {www.igi-global.com/article/taxonomy-censors-anti-censors/65552},
	doi = {10.4018/jep.2012040104},
	abstract = {The tug-of-war on the Internet between censor and anti-censor technologies is intensifying. With an aim to raise awareness on Internet censorship and its circumvention, this paper and its companion Part II present a conceptual study of Internet censorship and anti-censorship. This first paper focuse...},
	language = {en},
	number = {2},
	urldate = {2021-03-26},
	journal = {International Journal of E-Politics (IJEP)},
	author = {Leberknight, Christopher S. and Chiang, Mung and Wong, Felix Ming Fai},
	month = apr,
	year = {2012},
	note = {Publisher: IGI Global},
	pages = {52--64},
}

@misc{postel_rfc_1983,
	title = {{RFC} 862: {Echo} {Protocol}},
	shorttitle = {{RFC} 862},
	url = {https://tools.ietf.org/html/rfc862},
	language = {en},
	urldate = {2021-03-24},
	publisher = {Internet Engineering Task Force},
	author = {Postel, J.},
	month = may,
	year = {1983},
}

@misc{raman_hyperquack-v1_2020,
	type = {Documentation},
	title = {Hyperquack-v1},
	shorttitle = {Censored {Planet} {Docs}},
	url = {https://censoredplanet.readthedocs.io/en/latest/hyperquackv1.html},
	language = {English},
	urldate = {2021-03-10},
	journal = {Censored Planet Observatory 2.0 documentation},
	author = {Raman, Ram Sundara},
	collaborator = {Ceccio, Nick and Tsai, Elisa and Evdokimov, Leonid and Virkud, Apurva and Ensafi, Roya},
	year = {2020},
}

@misc{ceccio_censoredplanetcensoredplanet_2021,
	title = {censoredplanet/censoredplanet},
	copyright = {BSD-3-Clause License         ,                 BSD-3-Clause License},
	url = {https://github.com/censoredplanet/censoredplanet},
	abstract = {This respository contains documentation about the raw data from the Censored Planet Observatory and includes code to analyze the data and run several useful observations.},
	urldate = {2021-03-10},
	publisher = {Censored Planet},
	author = {Ceccio, Nick and Virkud, Apurva and Tsai, Elisa and Raman, Ram Sundara},
	month = jan,
	year = {2021},
	note = {original-date: 2020-10-15T19:19:22Z},
}

@inproceedings{sarabi_characterizing_2018,
	address = {New York, NY, USA},
	series = {{IMC} '18},
	title = {Characterizing the {Internet} {Host} {Population} {Using} {Deep} {Learning}: {A} {Universal} and {Lightweight} {Numerical} {Embedding}},
	isbn = {978-1-4503-5619-0},
	shorttitle = {Characterizing the {Internet} {Host} {Population} {Using} {Deep} {Learning}},
	url = {http://doi.org/10.1145/3278532.3278545},
	doi = {10.1145/3278532.3278545},
	abstract = {In this paper, we present a framework to characterize Internet hosts using deep learning, using Internet scan data to produce numerical and lightweight (low-dimensional) representations of hosts. To do so we first develop a novel method for extracting binary tags from structured texts, the format of the scan data. We then use a variational autoencoder, an unsupervised neural network model, to construct low-dimensional embeddings of our high-dimensional binary representations. We show that these lightweight embeddings retain most of the information in our binary representations, while drastically reducing memory and computational requirements for large-scale analysis. These embeddings are also universal, in that the process used to generate them is unsupervised and does not rely on specific applications. This universality makes the embeddings broadly applicable to a variety of learning tasks whereby they can be used as input features. We present two such examples, (1) detecting and predicting malicious hosts, and (2) unmasking hidden host attributes, and compare the trained models in their performance, speed, robustness, and interpretability. We show that our embeddings can achieve high accuracy ({\textgreater}95\%) for these learning tasks, while being fast enough to enable host-level analysis at scale.},
	urldate = {2021-02-06},
	booktitle = {Proceedings of the {Internet} {Measurement} {Conference} 2018},
	publisher = {Association for Computing Machinery},
	author = {Sarabi, Armin and Liu, Mingyan},
	month = oct,
	year = {2018},
	keywords = {Host Embedding, Machine Learning, Network Measurement, embeddings},
	pages = {133--146},
}

@inproceedings{chen_software_2020,
	address = {New York, NY, USA},
	series = {{ICSE} '20},
	title = {Software visualization and deep transfer learning for effective software defect prediction},
	isbn = {978-1-4503-7121-6},
	url = {http://doi.org/10.1145/3377811.3380389},
	doi = {10.1145/3377811.3380389},
	abstract = {Software defect prediction aims to automatically locate defective code modules to better focus testing resources and human effort. Typically, software defect prediction pipelines are comprised of two parts: the first extracts program features, like abstract syntax trees, by using external tools, and the second applies machine learning-based classification models to those features in order to predict defective modules. Since such approaches depend on specific feature extraction tools, machine learning classifiers have to be custom-tailored to effectively build most accurate models. To bridge the gap between deep learning and defect prediction, we propose an end-to-end framework which can directly get prediction results for programs without utilizing feature-extraction tools. To that end, we first visualize programs as images, apply the self-attention mechanism to extract image features, use transfer learning to reduce the difference in sample distributions between projects, and finally feed the image files into a pre-trained, deep learning model for defect prediction. Experiments with 10 open source projects from the PROMISE dataset show that our method can improve cross-project and within-project defect prediction. Our code and data pointers are available at https://zenodo.org/record/3373409\#.XV0Oy5Mza35.},
	urldate = {2021-03-05},
	booktitle = {Proceedings of the {ACM}/{IEEE} 42nd {International} {Conference} on {Software} {Engineering}},
	publisher = {Association for Computing Machinery},
	author = {Chen, Jinyin and Hu, Keke and Yu, Yue and Chen, Zhuangzhi and Xuan, Qi and Liu, Yi and Filkov, Vladimir},
	month = jun,
	year = {2020},
	keywords = {cross-project defect prediction, deep transfer learning, self-attention, software visualization, within-project defect prediction},
	pages = {578--589},
}

@misc{sarabi_arsarabivae_2018,
	title = {arsarabi/vae},
	url = {https://github.com/arsarabi/vae},
	abstract = {Implementation of a variational autoencoder in TensorFlow},
	urldate = {2021-02-06},
	author = {Sarabi, Armin},
	month = dec,
	year = {2018},
	note = {original-date: 2018-09-21T13:45:01Z},
	keywords = {deep-learning, embeddings, latent-variable-models, variational-autoencoder},
}

@misc{sarabi_arsarabijsonvectorizer_2021,
	title = {arsarabi/jsonvectorizer},
	copyright = {MIT License         ,                 MIT License},
	url = {https://github.com/arsarabi/jsonvectorizer},
	abstract = {Tools for extracting vector representations of JSON documents},
	urldate = {2021-02-06},
	author = {Sarabi, Armin},
	month = jan,
	year = {2021},
	note = {original-date: 2018-05-09T13:08:41Z},
	keywords = {feature-extraction, json, json-schema, vectorization},
}

@inproceedings{sundara_raman_censored_2020,
	address = {New York, NY, USA},
	series = {{CCS} '20},
	title = {Censored {Planet}: {An} {Internet}-wide, {Longitudinal} {Censorship} {Observatory}},
	isbn = {978-1-4503-7089-9},
	shorttitle = {Censored {Planet}},
	url = {http://doi.org/10.1145/3372297.3417883},
	doi = {10.1145/3372297.3417883},
	abstract = {Remote censorship measurement techniques offer capabilities for monitoring Internet reachability around the world. However, operating these techniques continuously is labor-intensive and requires specialized knowledge and synchronization, leading to limited adoption. In this paper, we introduce Censored Planet, an online censorship measurement platform that collects and analyzes measurements from ongoing deployments of four remote measurement techniques (Augur, Satellite/Iris, Quack, and Hyperquack). Censored Planet adopts a modular design that supports synchronized baseline measurements on six Internet protocols as well as customized measurements that target specific countries and websites. Censored Planet has already collected and published more than 21.8 billion data points of longitudinal network observations over 20 months of operation. Censored Planet complements existing censorship measurement platforms such as OONI and ICLab by offering increased scale, coverage, and continuity. We introduce a new representative censorship metric and show how time series analysis can be applied to Censored Planet's longitudinal measurements to detect 15 prominent censorship events, two-thirds of which have not been reported previously. Using trend analysis, we find increasing censorship activity in more than 100 countries, and we identify 11 categories of websites facing increasing censorship, including provocative attire, human rights issues, and news media. We hope that the continued publication of Censored Planet data helps counter the proliferation of growing restrictions to online freedom.},
	urldate = {2021-02-06},
	booktitle = {Proceedings of the 2020 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Sundara Raman, Ram and Shenoy, Prerana and Kohls, Katharina and Ensafi, Roya},
	month = oct,
	year = {2020},
	keywords = {availability, censorship, empirical security, measurement},
	pages = {49--66},
}

@inproceedings{dainotti2011analysis,
	title={Analysis of country-wide {Internet} outages caused by censorship},
	author={Dainotti, Alberto and Squarcella, Claudio and Aben, Emile and Claffy, Kimberly C and Chiesa, Marco and Russo, Michele and Pescap{\'e}, Antonio},
	booktitle={Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference},
	pages={1--18},
	year={2011}
}

@inproceedings{aryan2013internet,
  title={{Internet} censorship in {Iran}: A first look},
  author={Aryan, Simurgh and Aryan, Homa and Halderman, J Alex},
  booktitle={3rd USENIX Workshop on Free and Open Communications on the Internet (FOCI 13)},
  year={2013}
}

@inproceedings{nabi2013anatomy,
  title={The anatomy of {Web} censorship in {Pakistan}},
  author={Nabi, Zubair},
  booktitle={3rd USENIX Workshop on Free and Open Communications on the Internet (FOCI 13)},
  year={2013}
}


@inproceedings{luong2015effective,
  title={Effective Approaches to Attention-based Neural Machine Translation},
  author={Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
  booktitle={Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing},
  pages={1412--1421},
  year={2015}
}


@article{chakraborty2021deep,
  title={Deep learning based vulnerability detection: Are we there yet},
  author={Chakraborty, Saikat and Krishna, Rahul and Ding, Yangruibo and Ray, Baishakhi},
  journal={IEEE Transactions on Software Engineering},
  year={2021},
  publisher={IEEE}
}

@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}
